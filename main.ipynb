{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e9b5986-af32-4dd6-9452-fdeced53ebc8",
   "metadata": {
    "id": "77c8ac2e-eb68-4b84-85fe-3a6661eba976"
   },
   "source": [
    "Here a vector store solution will be integrated into a RAG pipeline and it will be evaluated using numerical RAG evaluation techniques incorporating LLM-as-a-Judge metrics.\n",
    " \n",
    "- RAG pipeline will be numerically evaluated.\n",
    "\n",
    "# Questions:\n",
    "- Should the pipeline pass these objectives? Is the judge LLM sufficient for evaluating the pipeline? Does a particular metric even matter for the use case?\n",
    "- If the vectorstore-as-a-memory component is left in our chain, will it still pass the evaluation? Additionally, is the evaluation useful for assessing vectorstore-as-a-memory performance?\n",
    "\n",
    "### **Environment Setup:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "w_A3rZOrIeQD",
   "metadata": {
    "id": "w_A3rZOrIeQD",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %pip install -q langchain requests sentence-transformers gradio rich\n",
    "# %pip install -q faiss ragas\n",
    "\n",
    "## If a typing-extensions issue is encountered, restart your runtime and try again\n",
    "\n",
    "from functools import partial\n",
    "from huggingface_hub import list_models\n",
    "import json\n",
    "from langchain_core.embeddings.embeddings import Embeddings\n",
    "from langchain_core.language_models.chat_models import BaseChatModel\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompt_values import ChatPromptValue\n",
    "from langchain_core.runnables.config import RunnableConfig\n",
    "import os\n",
    "from pydantic import BaseModel, ConfigDict, PrivateAttr\n",
    "from rich.console import Console\n",
    "from rich.style import Style\n",
    "import requests\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from typing import List, Optional\n",
    "\n",
    "console = Console()\n",
    "base_style = Style(color=\"#76B900\", bold=True)\n",
    "norm_style = Style(bold=True)\n",
    "pprint = partial(console.print, style=base_style)\n",
    "pprint2 = partial(console.print, style=norm_style)\n",
    "\n",
    "# Gemini API Configuration\n",
    "GEMINI_API_URL = \"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent\"\n",
    "# Secret GEMINI_API_KEY environment variable to be set beforehand\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "if not GEMINI_API_KEY:\n",
    "    raise ValueError(\"GEMINI_API_KEY environment variable not set.\")\n",
    "    exit()\n",
    "\n",
    "class SentenceTransformersEmbeddings(BaseModel, Embeddings):\n",
    "    \"\"\"Wrapper for Gemini Embeddings.\"\"\"\n",
    "\n",
    "    model_config = ConfigDict(arbitrary_types_allowed=True)\n",
    "    model: str = \"Alibaba-NLP/gte-base-en-v1.5\"\n",
    "    embedder: SentenceTransformer = None\n",
    "    \n",
    "    def __init__(self, model: str = \"Alibaba-NLP/gte-base-en-v1.5\", trust_remote_code: Optional[bool] = False):\n",
    "        \"\"\"\n",
    "        Initialize the SentenceTransformersEmbeddings class using a SentenceTransformer model.\n",
    "        :param model: Name of the pre-trained model to load from SentenceTransformers.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.embedder = SentenceTransformer(model, trust_remote_code=trust_remote_code)\n",
    "\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        \"\"\"\n",
    "        Generate embeddings for a list of texts.\n",
    "        :param texts: List of input texts.\n",
    "        :return: List of embeddings (one for each text).\n",
    "        \"\"\"\n",
    "        if not texts:\n",
    "            pprint2(\"\")\n",
    "            raise ValueError(\"Input texts list cannot be empty.\")\n",
    "        return self.embedder.encode(texts, convert_to_tensor=False).tolist()\n",
    "\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        \"\"\"\n",
    "        Generate embedding for a single query.\n",
    "        :param text: Input query text.\n",
    "        :return: Embedding for the query as a list of floats.\n",
    "        \"\"\"\n",
    "        if not text:\n",
    "            raise ValueError(\"Input text cannot be empty.\")\n",
    "        return self.embedder.encode(text, convert_to_tensor=False).tolist()\n",
    "\n",
    "    @classmethod\n",
    "    def get_available_models(cls, search_term: str = \"sentence-transformers\"):\n",
    "        \"\"\"\n",
    "        Dynamically fetch available SentenceTransformer models from Hugging Face Model Hub.\n",
    "        :param search_term: Search term to filter relevant models (default: 'sentence-transformers').\n",
    "        :return: List of model names.\n",
    "        \"\"\"\n",
    "        models = list_models(author=search_term)\n",
    "        return [model.modelId for model in models]\n",
    "\n",
    "class GeminiChat(BaseChatModel):\n",
    "    \"\"\"Wrapper for Gemini Chat.\"\"\"\n",
    "\n",
    "    model: str = \"gemini-1.5-flash\"\n",
    "    temperature: float = 1.0\n",
    "    max_tokens: Optional[int] = None\n",
    "\n",
    "    # Declare private attributes\n",
    "    _api_url: str = PrivateAttr()\n",
    "    _headers: dict = PrivateAttr()\n",
    "    \n",
    "    def __init__(self, model: str = \"gemini-1.5-flash\", temperature: float = 1.0, max_tokens: Optional[int] = None):\n",
    "        super().__init__(model=model, temperature=temperature, max_tokens=max_tokens)\n",
    "        \n",
    "        # Initialize private attributes\n",
    "        self._api_url = f\"{GEMINI_API_URL}\"\n",
    "        self._headers = {\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "\n",
    "    def _llm_type(self):\n",
    "        return \"gemini-1.5-flash\"\n",
    "    \n",
    "    def _generate(self, prompt: ChatPromptValue, stop: Optional[List[str]] = None) -> str:\n",
    "        payload = {\n",
    "            \"contents\": [\n",
    "                {\n",
    "                    \"parts\": [{\"text\": prompt.messages[0].content}]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        if self.max_tokens is not None:  # Include max_tokens only if it's valid\n",
    "            payload[\"max_tokens\"] = self.max_tokens\n",
    "        response = requests.post(\n",
    "            f\"{self._api_url}?key={GEMINI_API_KEY}\",\n",
    "            headers=self._headers,\n",
    "            json=payload\n",
    "        )\n",
    "        if response.status_code == 200:\n",
    "            try:\n",
    "                return response.json()[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
    "            except Exception as e:\n",
    "                pprint2(f\"Error parsing response JSON: {repr(e)}\")\n",
    "                return \"\"\n",
    "        else:\n",
    "            try:\n",
    "                error_data = response.json()\n",
    "                pprint2(f\"Error {response.status_code}: {error_data}\")\n",
    "            except Exception as e:\n",
    "                pprint2(f\"Error {response.status_code}: {repr(e)}\")\n",
    "            return \"\"\n",
    "            \n",
    "    def invoke(self, prompt: str, stop: Optional[List[str]] = None) -> str:\n",
    "        return self._generate(prompt, stop)\n",
    "\n",
    "    def stream(self, input_text: ChatPromptValue, config: Optional[RunnableConfig]):\n",
    "        # Simulate streaming by yielding tokens from the response\n",
    "        response = self._generate(input_text)\n",
    "        for token in response:\n",
    "            yield token\n",
    "    \n",
    "    @property\n",
    "    def _identifying_params(self):\n",
    "        return {\n",
    "            \"model\": self.model,\n",
    "            \"temperature\": self.temperature,\n",
    "            \"max_tokens\": self.max_tokens\n",
    "        }\n",
    "\n",
    "    @classmethod\n",
    "    def get_available_models(cls):\n",
    "        pprint2(\"GeminiChat does not support listing available models via API.\")\n",
    "        return []\n",
    "\n",
    "# Instantiate SentenceTransformersEmbeddings and GeminiChat\n",
    "embedder = SentenceTransformersEmbeddings(model=\"Alibaba-NLP/gte-base-en-v1.5\", trust_remote_code=True)\n",
    "instruct_llm = GeminiChat(model=\"gemini-1.5-flash\", temperature=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zEgV11oZmJGg",
   "metadata": {
    "id": "zEgV11oZmJGg"
   },
   "source": [
    "## 1. Pre-Release Evaluation\n",
    "\n",
    "- **Typical Use Inspection:**\n",
    "\n",
    "- **Edge Case Inspection:**\n",
    "\n",
    "- **Progressive Rollout:**\n",
    "\n",
    "## 2. LLM-as-a-Judge Formulation\n",
    "\n",
    "- LLM simulates a range of interaction scenarios and generate synthetic data, allowing an evaluation developer to generate targeted inputs to eliciting a range of behaviors from your chatbot.\n",
    "\n",
    "- The chatbot's correspondence/retrieval on synthetic data can be evaluated or parsed by an LLM and a consistent output format such as \"Pass\"/\"Fail\", similarity, or extraction can be enforced.\n",
    "\n",
    "- Many such results can be aggregated and a metric can be derived which explains something like \"% of passing evaluations\", \"average number of relevant details from the sources\", \"average cosine similarity\", etc.\n",
    "\n",
    "This idea of using LLMs to test out and quantify chatbot quality, known as [**\"LLM-as-a-Judge,\"**](https://arxiv.org/abs/2306.05685) allows for easy test specifications that align closely with human judgment and can be fine-tuned and replicated at scale.\n",
    "\n",
    "**Popular frameworks for off-the-shelf judge formulations:**\n",
    "- [**RAGAs (RAG Assessment)**](https://docs.ragas.io/en/stable/)\n",
    "- [**LangChain Evaluators**](https://python.langchain.com/docs/guides/evaluation/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66b947e",
   "metadata": {},
   "source": [
    "### 3. RAG For Conversation History"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c34a212",
   "metadata": {},
   "source": [
    "### 3.1 Constructing Our Vector Store Retriever\n",
    "**Vector Stores**, or vector storage systems, abstract away most of the low-level details of the embedding/comparison strategies and provide a simple interface to load and compare vectors.\n",
    "\n",
    "Now we start with the [**FAISS vector store**](https://python.langchain.com/docs/integrations/vectorstores/faiss), which integrates a LangChain-compatable Embedding model with the [**FAISS (Facebook AI Similarity Search)**](https://github.com/facebookresearch/faiss) library to make the process fast and scalable on our local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64893a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 136 ms, sys: 123 ms, total: 259 ms\n",
      "Wall time: 387 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## ^^ This cell will be timed to see how long the conversation embedding takes\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "conversation = [  ## This conversation was generated partially by an AI system, and modified to exhibit desirable properties\n",
    "    \"[User]  Hello! My name is Beras, and I'm a big blue bear! Can you please tell me about the rocky mountains?\",\n",
    "    \"[Agent] The Rocky Mountains are a beautiful and majestic range of mountains that stretch across North America\",\n",
    "    \"[Beras] Wow, that sounds amazing! Ive never been to the Rocky Mountains before, but Ive heard many great things about them.\",\n",
    "    \"[Agent] I hope you get to visit them someday, Beras! It would be a great adventure for you!\"\n",
    "    \"[Beras] Thank you for the suggestion! Ill definitely keep it in mind for the future.\",\n",
    "    \"[Agent] In the meantime, you can learn more about the Rocky Mountains by doing some research online or watching documentaries about them.\"\n",
    "    \"[Beras] I live in the arctic, so I'm not used to the warm climate there. I was just curious, ya know!\",\n",
    "    \"[Agent] Absolutely! Lets continue the conversation and explore more about the Rocky Mountains and their significance!\"\n",
    "]\n",
    "\n",
    "# Streamlined from_texts FAISS vectorstore construction from text list\n",
    "convstore = FAISS.from_texts(conversation, embedding=embedder)\n",
    "retriever = convstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7875200d",
   "metadata": {},
   "source": [
    "The retriever can now be used like any other LangChain runnable to query the vector store for some relevant documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b567d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain.document_transformers import LongContextReorder\n",
    "\n",
    "## Utility Runnable/Method\n",
    "def RPrint(preface=\"\"):\n",
    "    \"\"\"Simple passthrough \"prints, then returns\" chain\"\"\"\n",
    "    def print_and_return(x, preface):\n",
    "        if preface: print(preface, end=\"\")\n",
    "        pprint(x)\n",
    "        return x\n",
    "    return RunnableLambda(partial(print_and_return, preface=preface))\n",
    "\n",
    "def docs2str(docs, title=\"Document\"):\n",
    "    \"\"\"Useful utility for making chunks into context string. Optional, but useful\"\"\"\n",
    "    out_str = \"\"\n",
    "    for doc in docs:\n",
    "        doc_name = getattr(doc, 'metadata', {}).get('Title', title)\n",
    "        if doc_name: out_str += f\"[Quote from {doc_name}] \"\n",
    "        out_str += getattr(doc, 'page_content', str(doc)) + \"\\n\"\n",
    "    return out_str\n",
    "\n",
    "## Optional; Reorders longer documents to center of output text\n",
    "long_reorder = RunnableLambda(LongContextReorder().transform_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5feecc1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Beras lives in the arctic.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mBeras lives in the arctic.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "context_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Answer the question using only the context\"\n",
    "    \"\\n\\nRetrieved Context: {context}\"\n",
    "    \"\\n\\nUser Question: {question}\"\n",
    "    \"\\nAnswer the user conversationally. User is not aware of context.\"\n",
    ")\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        'context': convstore.as_retriever() | long_reorder | docs2str,\n",
    "        'question': (lambda x:x)\n",
    "    }\n",
    "    | context_prompt\n",
    "    # | RPrint()\n",
    "    | instruct_llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "pprint(chain.invoke(\"Where does Beras live?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f73b17c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">According to the conversation, the Rocky Mountains are a range of mountains that stretch across North America.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mAccording to the conversation, the Rocky Mountains are a range of mountains that stretch across North America.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint(chain.invoke(\"Where are the Rocky Mountains?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb600f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Based on the conversation, the Rocky Mountains are in North America.  The provided text doesn't say whether they </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">are close to California or not.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mBased on the conversation, the Rocky Mountains are in North America.  The provided text doesn't say whether they \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mare close to California or not.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint(chain.invoke(\"Where are the Rocky Mountains? Are they close to California?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b345c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Based on the conversation, Beras lives in the Arctic.  The Rocky Mountains are in North America.  The exact </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">distance isn't specified, but it's a considerable distance given their differing locations.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mBased on the conversation, Beras lives in the Arctic.  The Rocky Mountains are in North America.  The exact \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mdistance isn't specified, but it's a considerable distance given their differing locations.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pprint(chain.invoke(\"How far away is Beras from the Rocky Mountains?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5ac9cf",
   "metadata": {},
   "source": [
    "### 3.2 Automatic Conversation Storage\n",
    "\n",
    "Now we see how our vector store memory unit should function, we can perform one last integration to allow our conversation to add new entries to our conversation: a runnable that calls the `add_texts` method for us to update the store state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71312845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">That's great you're excited!  While we're talking about the Rocky Mountains,  I don't think ice cream was mentioned</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">in our previous conversation. Are you thinking of a different place?</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mThat's great you're excited!  While we're talking about the Rocky Mountains,  I don't think ice cream was mentioned\u001b[0m\n",
       "\u001b[1;38;2;118;185;0min our previous conversation. Are you thinking of a different place?\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Based on our conversation, it sounds like ice cream is your favorite food!</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mBased on our conversation, it sounds like ice cream is your favorite food!\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Oh, whoops!  My apologies! I must have gotten that wrong.  I guess I jumped to conclusions based on your excitement</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">about ice cream.  Honey sounds delicious too!</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mOh, whoops!  My apologies! I must have gotten that wrong.  I guess I jumped to conclusions based on your excitement\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mabout ice cream.  Honey sounds delicious too!\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Well, you seem pretty excited about ice cream, so I'm going to guess that's still your favorite!  But I learned my </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">lesson about jumping to conclusions!</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mWell, you seem pretty excited about ice cream, so I'm going to guess that's still your favorite!  But I learned my \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mlesson about jumping to conclusions!\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableAssign\n",
    "from operator import itemgetter\n",
    "\n",
    "## Reset knowledge base and define what it means to add more messages.\n",
    "convstore = FAISS.from_texts(conversation, embedding=embedder)\n",
    "\n",
    "def save_memory_and_get_output(d, vstore):\n",
    "    \"\"\"Accepts 'input'/'output' dictionary and saves to convstore\"\"\"\n",
    "    vstore.add_texts([f\"User said {d.get('input')}\", f\"Agent said {d.get('output')}\"])\n",
    "    return d.get('output')\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Answer the question using only the context\"\n",
    "    \"\\n\\nRetrieved Context: {context}\"\n",
    "    \"\\n\\nUser Question: {input}\"\n",
    "    \"\\nAnswer the user conversationally. Make sure the conversation flows naturally.\\n\"\n",
    "    \"[Agent]\"\n",
    ")\n",
    "\n",
    "conv_chain = (\n",
    "    {\n",
    "        'context': convstore.as_retriever() | long_reorder | docs2str,\n",
    "        'input': (lambda x:x)\n",
    "    }\n",
    "    | RunnableAssign({'output' : chat_prompt | instruct_llm | StrOutputParser()})\n",
    "    | partial(save_memory_and_get_output, vstore=convstore)\n",
    ")\n",
    "pprint(conv_chain.invoke(\"I'm glad you agree! I can't wait to get some ice cream there! It's such a good food!\"))\n",
    "print()\n",
    "pprint(conv_chain.invoke(\"Can you guess what my favorite food is?\"))\n",
    "print()\n",
    "pprint(conv_chain.invoke(\"Actually, my favorite is honey! Not sure where you got that idea?\"))\n",
    "print()\n",
    "pprint(conv_chain.invoke(\"I see! Fair enough! Do you know my favorite food now?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745f951a",
   "metadata": {},
   "source": [
    "## 4. RAG For Document Chunk Retrieval\n",
    "\n",
    "The idea that data chunks can be embedded and searched through is flabbergasting. Applying RAG with documents is a double-edged sword; it may **seem** to work well out of the box but requires some extra care when optimizing it for truly reliable performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0908a5",
   "metadata": {},
   "source": [
    "### 4.1 Loading And Chunking Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc361f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Documents\n",
      "Chunking Documents\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Available Documents:</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\"> - Attention Is All You Need</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\"> - BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\"> - Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\"> - MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">sources and discrete reasoning</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\"> - Mistral 7B</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\"> - Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\"> - ReAct: Synergizing Reasoning and Acting in Language Models</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\"> - High-Resolution Image Synthesis with Latent Diffusion Models</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\"> - Learning Transferable Visual Models From Natural Language Supervision </span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mAvailable Documents:\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m - Attention Is All You Need\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m - BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m - Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m - MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge \u001b[0m\n",
       "\u001b[1;38;2;118;185;0msources and discrete reasoning\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m - Mistral 7B\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m - Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m - ReAct: Synergizing Reasoning and Acting in Language Models\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m - High-Resolution Image Synthesis with Latent Diffusion Models\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m - Learning Transferable Visual Models From Natural Language Supervision \u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0\n",
      " - # Chunks: 35\n",
      " - Metadata: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">{</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Published'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'2023-08-02'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Title'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Attention Is All You Need'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Authors'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Kaiser, Illia Polosukhin'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Summary'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'The dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">networks in an encoder-decoder configuration. The best\\nperforming models also connect the encoder and decoder </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">through an attention\\nmechanism. We propose a new simple network architecture, the Transformer, based\\nsolely on </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks show these models to be\\nsuperior in quality while being more parallelizable and requiring </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">significantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014\\nEnglish-to-German translation </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">task, improving over the existing best results,\\nincluding ensembles by over 2 BLEU. On the WMT 2014 </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">English-to-French\\ntranslation task, our model establishes a new single-model state-of-the-art\\nBLEU score of 41.8 </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">after training for 3.5 days on eight GPUs, a small fraction\\nof the training costs of the best models from the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">literature. We show that the\\nTransformer generalizes well to other tasks by applying it successfully to\\nEnglish </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">constituency parsing both with large and limited training data.'</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0m{\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Published'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'2023-08-02'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Title'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Attention Is All You Need'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Authors'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz \u001b[0m\n",
       "\u001b[32mKaiser, Illia Polosukhin'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Summary'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'The dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural \u001b[0m\n",
       "\u001b[32mnetworks in an encoder-decoder configuration. The best\\nperforming models also connect the encoder and decoder \u001b[0m\n",
       "\u001b[32mthrough an attention\\nmechanism. We propose a new simple network architecture, the Transformer, based\\nsolely on \u001b[0m\n",
       "\u001b[32mattention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation\u001b[0m\n",
       "\u001b[32mtasks show these models to be\\nsuperior in quality while being more parallelizable and requiring \u001b[0m\n",
       "\u001b[32msignificantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014\\nEnglish-to-German translation \u001b[0m\n",
       "\u001b[32mtask, improving over the existing best results,\\nincluding ensembles by over 2 BLEU. On the WMT 2014 \u001b[0m\n",
       "\u001b[32mEnglish-to-French\\ntranslation task, our model establishes a new single-model state-of-the-art\\nBLEU score of 41.8 \u001b[0m\n",
       "\u001b[32mafter training for 3.5 days on eight GPUs, a small fraction\\nof the training costs of the best models from the \u001b[0m\n",
       "\u001b[32mliterature. We show that the\\nTransformer generalizes well to other tasks by applying it successfully to\\nEnglish \u001b[0m\n",
       "\u001b[32mconstituency parsing both with large and limited training data.'\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document 1\n",
      " - # Chunks: 45\n",
      " - Metadata: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">{</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Published'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'2019-05-24'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Title'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Authors'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Summary'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'We introduce a new language representation model called BERT, which stands\\nfor Bidirectional </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Encoder Representations from Transformers. Unlike recent\\nlanguage representation models, BERT is designed to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">pre-train deep\\nbidirectional representations from unlabeled text by jointly conditioning on\\nboth left and right </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">context in all layers. As a result, the pre-trained BERT\\nmodel can be fine-tuned with just one additional output </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">layer to create\\nstate-of-the-art models for a wide range of tasks, such as question answering\\nand language </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">inference, without substantial task-specific architecture\\nmodifications.\\n  BERT is conceptually simple and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">empirically powerful. It obtains new\\nstate-of-the-art results on eleven natural language processing tasks, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">including\\npushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI\\naccuracy to 86.7% (4.6% </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">absolute improvement), SQuAD v1.1 question answering\\nTest F1 to 93.2 (1.5 point absolute improvement) and SQuAD </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">v2.0 Test F1 to 83.1\\n(5.1 point absolute improvement).'</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0m{\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Published'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'2019-05-24'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Title'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Authors'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Summary'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'We introduce a new language representation model called BERT, which stands\\nfor Bidirectional \u001b[0m\n",
       "\u001b[32mEncoder Representations from Transformers. Unlike recent\\nlanguage representation models, BERT is designed to \u001b[0m\n",
       "\u001b[32mpre-train deep\\nbidirectional representations from unlabeled text by jointly conditioning on\\nboth left and right \u001b[0m\n",
       "\u001b[32mcontext in all layers. As a result, the pre-trained BERT\\nmodel can be fine-tuned with just one additional output \u001b[0m\n",
       "\u001b[32mlayer to create\\nstate-of-the-art models for a wide range of tasks, such as question answering\\nand language \u001b[0m\n",
       "\u001b[32minference, without substantial task-specific architecture\\nmodifications.\\n  BERT is conceptually simple and \u001b[0m\n",
       "\u001b[32mempirically powerful. It obtains new\\nstate-of-the-art results on eleven natural language processing tasks, \u001b[0m\n",
       "\u001b[32mincluding\\npushing the GLUE score to 80.5% \u001b[0m\u001b[32m(\u001b[0m\u001b[32m7.7% point absolute improvement\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, MultiNLI\\naccuracy to 86.7% \u001b[0m\u001b[32m(\u001b[0m\u001b[32m4.6% \u001b[0m\n",
       "\u001b[32mabsolute improvement\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, SQuAD v1.1 question answering\\nTest F1 to 93.2 \u001b[0m\u001b[32m(\u001b[0m\u001b[32m1.5 point absolute improvement\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and SQuAD \u001b[0m\n",
       "\u001b[32mv2.0 Test F1 to 83.1\\n\u001b[0m\u001b[32m(\u001b[0m\u001b[32m5.1 point absolute improvement\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.'\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document 2\n",
      " - # Chunks: 46\n",
      " - Metadata: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">{</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Published'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'2021-04-12'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Title'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Authors'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, Sebastian Riedel, Douwe Kiela'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Summary'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Large pre-trained language models have been shown to store factual knowledge\\nin their parameters, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and achieve state-of-the-art results when fine-tuned on\\ndownstream NLP tasks. However, their ability to access and</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">precisely manipulate\\nknowledge is still limited, and hence on knowledge-intensive tasks, their\\nperformance lags </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">behind task-specific architectures. Additionally, providing\\nprovenance for their decisions and updating their </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">world knowledge remain open\\nresearch problems. Pre-trained models with a differentiable access mechanism </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">to\\nexplicit non-parametric memory can overcome this issue, but have so far been\\nonly investigated for extractive </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">downstream tasks. We explore a general-purpose\\nfine-tuning recipe for retrieval-augmented generation (RAG) -- </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">models which\\ncombine pre-trained parametric and non-parametric memory for language\\ngeneration. We introduce RAG </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">models where the parametric memory is a\\npre-trained seq2seq model and the non-parametric memory is a dense vector </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">index\\nof Wikipedia, accessed with a pre-trained neural retriever. We compare two RAG\\nformulations, one which </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">conditions on the same retrieved passages across the\\nwhole generated sequence, the other can use different </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">passages per token. We\\nfine-tune and evaluate our models on a wide range of knowledge-intensive NLP\\ntasks and set</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the state-of-the-art on three open domain QA tasks, outperforming\\nparametric seq2seq models and task-specific </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">retrieve-and-extract architectures.\\nFor language generation tasks, we find that RAG models generate more </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">specific,\\ndiverse and factual language than a state-of-the-art parametric-only seq2seq\\nbaseline.'</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0m{\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Published'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'2021-04-12'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Title'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Authors'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, \u001b[0m\n",
       "\u001b[32mHeinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, Sebastian Riedel, Douwe Kiela'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Summary'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Large pre-trained language models have been shown to store factual knowledge\\nin their parameters, \u001b[0m\n",
       "\u001b[32mand achieve state-of-the-art results when fine-tuned on\\ndownstream NLP tasks. However, their ability to access and\u001b[0m\n",
       "\u001b[32mprecisely manipulate\\nknowledge is still limited, and hence on knowledge-intensive tasks, their\\nperformance lags \u001b[0m\n",
       "\u001b[32mbehind task-specific architectures. Additionally, providing\\nprovenance for their decisions and updating their \u001b[0m\n",
       "\u001b[32mworld knowledge remain open\\nresearch problems. Pre-trained models with a differentiable access mechanism \u001b[0m\n",
       "\u001b[32mto\\nexplicit non-parametric memory can overcome this issue, but have so far been\\nonly investigated for extractive \u001b[0m\n",
       "\u001b[32mdownstream tasks. We explore a general-purpose\\nfine-tuning recipe for retrieval-augmented generation \u001b[0m\u001b[32m(\u001b[0m\u001b[32mRAG\u001b[0m\u001b[32m)\u001b[0m\u001b[32m -- \u001b[0m\n",
       "\u001b[32mmodels which\\ncombine pre-trained parametric and non-parametric memory for language\\ngeneration. We introduce RAG \u001b[0m\n",
       "\u001b[32mmodels where the parametric memory is a\\npre-trained seq2seq model and the non-parametric memory is a dense vector \u001b[0m\n",
       "\u001b[32mindex\\nof Wikipedia, accessed with a pre-trained neural retriever. We compare two RAG\\nformulations, one which \u001b[0m\n",
       "\u001b[32mconditions on the same retrieved passages across the\\nwhole generated sequence, the other can use different \u001b[0m\n",
       "\u001b[32mpassages per token. We\\nfine-tune and evaluate our models on a wide range of knowledge-intensive NLP\\ntasks and set\u001b[0m\n",
       "\u001b[32mthe state-of-the-art on three open domain QA tasks, outperforming\\nparametric seq2seq models and task-specific \u001b[0m\n",
       "\u001b[32mretrieve-and-extract architectures.\\nFor language generation tasks, we find that RAG models generate more \u001b[0m\n",
       "\u001b[32mspecific,\\ndiverse and factual language than a state-of-the-art parametric-only seq2seq\\nbaseline.'\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document 3\n",
      " - # Chunks: 40\n",
      " - Metadata: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">{</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Published'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'2022-05-01'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Title'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">knowledge sources and discrete reasoning'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Authors'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Ehud Karpas, Omri Abend, Yonatan Belinkov, Barak Lenz, Opher Lieber, Nir Ratner, Yoav Shoham, Hofit</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Bata, Yoav Levine, Kevin Leyton-Brown, Dor Muhlgay, Noam Rozen, Erez Schwartz, Gal Shachaf, Shai Shalev-Shwartz, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Amnon Shashua, Moshe Tenenholtz'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Summary'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Huge language models (LMs) have ushered in a new era for AI, serving as a\\ngateway to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">natural-language-based knowledge tasks. Although an essential\\nelement of modern AI, LMs are also inherently </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">limited in a number of ways. We\\ndiscuss these limitations and how they can be avoided by adopting a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">systems\\napproach. Conceptualizing the challenge as one that involves knowledge and\\nreasoning in addition to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">linguistic processing, we define a flexible\\narchitecture with multiple neural models, complemented by discrete </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">knowledge\\nand reasoning modules. We describe this neuro-symbolic architecture, dubbed the\\nModular Reasoning, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Knowledge and Language (MRKL, pronounced \"miracle\") system,\\nsome of the technical challenges in implementing it, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and Jurassic-X, AI21 Labs\\'\\nMRKL system implementation.'</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0m{\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Published'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'2022-05-01'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Title'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external \u001b[0m\n",
       "\u001b[32mknowledge sources and discrete reasoning'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Authors'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Ehud Karpas, Omri Abend, Yonatan Belinkov, Barak Lenz, Opher Lieber, Nir Ratner, Yoav Shoham, Hofit\u001b[0m\n",
       "\u001b[32mBata, Yoav Levine, Kevin Leyton-Brown, Dor Muhlgay, Noam Rozen, Erez Schwartz, Gal Shachaf, Shai Shalev-Shwartz, \u001b[0m\n",
       "\u001b[32mAmnon Shashua, Moshe Tenenholtz'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Summary'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Huge language models \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLMs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m have ushered in a new era for AI, serving as a\\ngateway to \u001b[0m\n",
       "\u001b[32mnatural-language-based knowledge tasks. Although an essential\\nelement of modern AI, LMs are also inherently \u001b[0m\n",
       "\u001b[32mlimited in a number of ways. We\\ndiscuss these limitations and how they can be avoided by adopting a \u001b[0m\n",
       "\u001b[32msystems\\napproach. Conceptualizing the challenge as one that involves knowledge and\\nreasoning in addition to \u001b[0m\n",
       "\u001b[32mlinguistic processing, we define a flexible\\narchitecture with multiple neural models, complemented by discrete \u001b[0m\n",
       "\u001b[32mknowledge\\nand reasoning modules. We describe this neuro-symbolic architecture, dubbed the\\nModular Reasoning, \u001b[0m\n",
       "\u001b[32mKnowledge and Language \u001b[0m\u001b[32m(\u001b[0m\u001b[32mMRKL, pronounced \"miracle\"\u001b[0m\u001b[32m)\u001b[0m\u001b[32m system,\\nsome of the technical challenges in implementing it, \u001b[0m\n",
       "\u001b[32mand Jurassic-X, AI21 Labs\\'\\nMRKL system implementation.'\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document 4\n",
      " - # Chunks: 21\n",
      " - Metadata: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">{</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Published'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'2023-10-10'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Title'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Mistral 7B'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Authors'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, Lélio Renard Lavaud, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Marie-Anne Lachaux, Pierre Stock, Teven Le Scao, Thibaut Lavril, Thomas Wang, Timothée Lacroix, William El Sayed'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Summary'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'We introduce Mistral 7B v0.1, a 7-billion-parameter language model engineered\\nfor superior </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">performance and efficiency. Mistral 7B outperforms Llama 2 13B\\nacross all evaluated benchmarks, and Llama 1 34B in</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">reasoning, mathematics, and\\ncode generation. Our model leverages grouped-query attention (GQA) for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">faster\\ninference, coupled with sliding window attention (SWA) to effectively handle\\nsequences of arbitrary length</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">with a reduced inference cost. We also provide a\\nmodel fine-tuned to follow instructions, Mistral 7B -- Instruct, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">that surpasses\\nthe Llama 2 13B -- Chat model both on human and automated benchmarks. Our\\nmodels are released </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">under the Apache 2.0 license.'</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0m{\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Published'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'2023-10-10'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Title'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Mistral 7B'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Authors'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, \u001b[0m\n",
       "\u001b[32mDiego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, Lélio Renard Lavaud, \u001b[0m\n",
       "\u001b[32mMarie-Anne Lachaux, Pierre Stock, Teven Le Scao, Thibaut Lavril, Thomas Wang, Timothée Lacroix, William El Sayed'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Summary'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'We introduce Mistral 7B v0.1, a 7-billion-parameter language model engineered\\nfor superior \u001b[0m\n",
       "\u001b[32mperformance and efficiency. Mistral 7B outperforms Llama 2 13B\\nacross all evaluated benchmarks, and Llama 1 34B in\u001b[0m\n",
       "\u001b[32mreasoning, mathematics, and\\ncode generation. Our model leverages grouped-query attention \u001b[0m\u001b[32m(\u001b[0m\u001b[32mGQA\u001b[0m\u001b[32m)\u001b[0m\u001b[32m for \u001b[0m\n",
       "\u001b[32mfaster\\ninference, coupled with sliding window attention \u001b[0m\u001b[32m(\u001b[0m\u001b[32mSWA\u001b[0m\u001b[32m)\u001b[0m\u001b[32m to effectively handle\\nsequences of arbitrary length\u001b[0m\n",
       "\u001b[32mwith a reduced inference cost. We also provide a\\nmodel fine-tuned to follow instructions, Mistral 7B -- Instruct, \u001b[0m\n",
       "\u001b[32mthat surpasses\\nthe Llama 2 13B -- Chat model both on human and automated benchmarks. Our\\nmodels are released \u001b[0m\n",
       "\u001b[32munder the Apache 2.0 license.'\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document 5\n",
      " - # Chunks: 44\n",
      " - Metadata: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">{</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Published'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'2023-12-24'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Title'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Authors'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Zhuohan Li, Dacheng Li, Eric P. Xing, Hao Zhang, Joseph E. Gonzalez, Ion Stoica'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Summary'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Evaluating large language model (LLM) based chat assistants is challenging\\ndue to their broad </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">capabilities and the inadequacy of existing benchmarks in\\nmeasuring human preferences. To address this, we explore</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">using strong LLMs as\\njudges to evaluate these models on more open-ended questions. We examine the\\nusage and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">limitations of LLM-as-a-judge, including position, verbosity, and\\nself-enhancement biases, as well as limited </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">reasoning ability, and propose\\nsolutions to mitigate some of them. We then verify the agreement between </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">LLM\\njudges and human preferences by introducing two benchmarks: MT-bench, a\\nmulti-turn question set; and Chatbot </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Arena, a crowdsourced battle platform. Our\\nresults reveal that strong LLM judges like GPT-4 can match both </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">controlled and\\ncrowdsourced human preferences well, achieving over 80% agreement, the same\\nlevel of agreement </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">between humans. Hence, LLM-as-a-judge is a scalable and\\nexplainable way to approximate human preferences, which </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">are otherwise very\\nexpensive to obtain. Additionally, we show our benchmark and traditional\\nbenchmarks complement</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">each other by evaluating several variants of LLaMA and\\nVicuna. The MT-bench questions, 3K expert votes, and 30K </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">conversations with\\nhuman preferences are publicly available </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">at\\nhttps://github.com/lm-sys/FastChat/tree/main/fastchat/llm_judge.'</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0m{\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Published'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'2023-12-24'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Title'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Authors'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, \u001b[0m\n",
       "\u001b[32mZhuohan Li, Dacheng Li, Eric P. Xing, Hao Zhang, Joseph E. Gonzalez, Ion Stoica'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Summary'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Evaluating large language model \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLM\u001b[0m\u001b[32m)\u001b[0m\u001b[32m based chat assistants is challenging\\ndue to their broad \u001b[0m\n",
       "\u001b[32mcapabilities and the inadequacy of existing benchmarks in\\nmeasuring human preferences. To address this, we explore\u001b[0m\n",
       "\u001b[32musing strong LLMs as\\njudges to evaluate these models on more open-ended questions. We examine the\\nusage and \u001b[0m\n",
       "\u001b[32mlimitations of LLM-as-a-judge, including position, verbosity, and\\nself-enhancement biases, as well as limited \u001b[0m\n",
       "\u001b[32mreasoning ability, and propose\\nsolutions to mitigate some of them. We then verify the agreement between \u001b[0m\n",
       "\u001b[32mLLM\\njudges and human preferences by introducing two benchmarks: MT-bench, a\\nmulti-turn question set; and Chatbot \u001b[0m\n",
       "\u001b[32mArena, a crowdsourced battle platform. Our\\nresults reveal that strong LLM judges like GPT-4 can match both \u001b[0m\n",
       "\u001b[32mcontrolled and\\ncrowdsourced human preferences well, achieving over 80% agreement, the same\\nlevel of agreement \u001b[0m\n",
       "\u001b[32mbetween humans. Hence, LLM-as-a-judge is a scalable and\\nexplainable way to approximate human preferences, which \u001b[0m\n",
       "\u001b[32mare otherwise very\\nexpensive to obtain. Additionally, we show our benchmark and traditional\\nbenchmarks complement\u001b[0m\n",
       "\u001b[32meach other by evaluating several variants of LLaMA and\\nVicuna. The MT-bench questions, 3K expert votes, and 30K \u001b[0m\n",
       "\u001b[32mconversations with\\nhuman preferences are publicly available \u001b[0m\n",
       "\u001b[32mat\\nhttps://github.com/lm-sys/FastChat/tree/main/fastchat/llm_judge.'\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document 6\n",
      " - # Chunks: 123\n",
      " - Metadata: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">{</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Published'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'2023-03-10'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Title'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'ReAct: Synergizing Reasoning and Acting in Language Models'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Authors'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, Yuan Cao'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Summary'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'While large language models (LLMs) have demonstrated impressive capabilities\\nacross tasks in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">language understanding and interactive decision making, their\\nabilities for reasoning (e.g. chain-of-thought </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">prompting) and acting (e.g.\\naction plan generation) have primarily been studied as separate topics. In </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">this\\npaper, we explore the use of LLMs to generate both reasoning traces and\\ntask-specific actions in an </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">interleaved manner, allowing for greater synergy\\nbetween the two: reasoning traces help the model induce, track, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and update\\naction plans as well as handle exceptions, while actions allow it to interface\\nwith external sources, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">such as knowledge bases or environments, to gather\\nadditional information. We apply our approach, named ReAct, to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">a diverse set of\\nlanguage and decision making tasks and demonstrate its effectiveness over\\nstate-of-the-art </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">baselines, as well as improved human interpretability and\\ntrustworthiness over methods without reasoning or acting</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">components.\\nConcretely, on question answering (HotpotQA) and fact verification (Fever),\\nReAct overcomes issues of</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">hallucination and error propagation prevalent in\\nchain-of-thought reasoning by interacting with a simple Wikipedia</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">API, and\\ngenerates human-like task-solving trajectories that are more interpretable than\\nbaselines without </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">reasoning traces. On two interactive decision making\\nbenchmarks (ALFWorld and WebShop), ReAct outperforms </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">imitation and\\nreinforcement learning methods by an absolute success rate of 34% and 10%\\nrespectively, while being</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">prompted with only one or two in-context examples.\\nProject site with code: https://react-lm.github.io'</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0m{\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Published'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'2023-03-10'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Title'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'ReAct: Synergizing Reasoning and Acting in Language Models'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Authors'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, Yuan Cao'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Summary'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'While large language models \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLMs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m have demonstrated impressive capabilities\\nacross tasks in \u001b[0m\n",
       "\u001b[32mlanguage understanding and interactive decision making, their\\nabilities for reasoning \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g. chain-of-thought \u001b[0m\n",
       "\u001b[32mprompting\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and acting \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g.\\naction plan generation\u001b[0m\u001b[32m)\u001b[0m\u001b[32m have primarily been studied as separate topics. In \u001b[0m\n",
       "\u001b[32mthis\\npaper, we explore the use of LLMs to generate both reasoning traces and\\ntask-specific actions in an \u001b[0m\n",
       "\u001b[32minterleaved manner, allowing for greater synergy\\nbetween the two: reasoning traces help the model induce, track, \u001b[0m\n",
       "\u001b[32mand update\\naction plans as well as handle exceptions, while actions allow it to interface\\nwith external sources, \u001b[0m\n",
       "\u001b[32msuch as knowledge bases or environments, to gather\\nadditional information. We apply our approach, named ReAct, to \u001b[0m\n",
       "\u001b[32ma diverse set of\\nlanguage and decision making tasks and demonstrate its effectiveness over\\nstate-of-the-art \u001b[0m\n",
       "\u001b[32mbaselines, as well as improved human interpretability and\\ntrustworthiness over methods without reasoning or acting\u001b[0m\n",
       "\u001b[32mcomponents.\\nConcretely, on question answering \u001b[0m\u001b[32m(\u001b[0m\u001b[32mHotpotQA\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and fact verification \u001b[0m\u001b[32m(\u001b[0m\u001b[32mFever\u001b[0m\u001b[32m)\u001b[0m\u001b[32m,\\nReAct overcomes issues of\u001b[0m\n",
       "\u001b[32mhallucination and error propagation prevalent in\\nchain-of-thought reasoning by interacting with a simple Wikipedia\u001b[0m\n",
       "\u001b[32mAPI, and\\ngenerates human-like task-solving trajectories that are more interpretable than\\nbaselines without \u001b[0m\n",
       "\u001b[32mreasoning traces. On two interactive decision making\\nbenchmarks \u001b[0m\u001b[32m(\u001b[0m\u001b[32mALFWorld and WebShop\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, ReAct outperforms \u001b[0m\n",
       "\u001b[32mimitation and\\nreinforcement learning methods by an absolute success rate of 34% and 10%\\nrespectively, while being\u001b[0m\n",
       "\u001b[32mprompted with only one or two in-context examples.\\nProject site with code: https://react-lm.github.io'\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document 7\n",
      " - # Chunks: 52\n",
      " - Metadata: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">{</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Published'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'2022-04-13'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Title'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'High-Resolution Image Synthesis with Latent Diffusion Models'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Authors'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, Björn Ommer'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Summary'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'By decomposing the image formation process into a sequential application of\\ndenoising </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">autoencoders, diffusion models (DMs) achieve state-of-the-art\\nsynthesis results on image data and beyond. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Additionally, their formulation\\nallows for a guiding mechanism to control the image generation process </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">without\\nretraining. However, since these models typically operate directly in pixel\\nspace, optimization of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">powerful DMs often consumes hundreds of GPU days and\\ninference is expensive due to sequential evaluations. To </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">enable DM training on\\nlimited computational resources while retaining their quality and flexibility,\\nwe apply </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">them in the latent space of powerful pretrained autoencoders. In\\ncontrast to previous work, training diffusion </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">models on such a representation\\nallows for the first time to reach a near-optimal point between </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">complexity\\nreduction and detail preservation, greatly boosting visual fidelity. By\\nintroducing cross-attention </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">layers into the model architecture, we turn\\ndiffusion models into powerful and flexible generators for general </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">conditioning\\ninputs such as text or bounding boxes and high-resolution synthesis becomes\\npossible in a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">convolutional manner. Our latent diffusion models (LDMs) achieve\\na new state of the art for image inpainting and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">highly competitive performance\\non various tasks, including unconditional image generation, semantic </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">scene\\nsynthesis, and super-resolution, while significantly reducing computational\\nrequirements compared to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">pixel-based DMs. Code is available at\\nhttps://github.com/CompVis/latent-diffusion .'</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0m{\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Published'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'2022-04-13'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Title'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'High-Resolution Image Synthesis with Latent Diffusion Models'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Authors'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, Björn Ommer'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Summary'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'By decomposing the image formation process into a sequential application of\\ndenoising \u001b[0m\n",
       "\u001b[32mautoencoders, diffusion models \u001b[0m\u001b[32m(\u001b[0m\u001b[32mDMs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m achieve state-of-the-art\\nsynthesis results on image data and beyond. \u001b[0m\n",
       "\u001b[32mAdditionally, their formulation\\nallows for a guiding mechanism to control the image generation process \u001b[0m\n",
       "\u001b[32mwithout\\nretraining. However, since these models typically operate directly in pixel\\nspace, optimization of \u001b[0m\n",
       "\u001b[32mpowerful DMs often consumes hundreds of GPU days and\\ninference is expensive due to sequential evaluations. To \u001b[0m\n",
       "\u001b[32menable DM training on\\nlimited computational resources while retaining their quality and flexibility,\\nwe apply \u001b[0m\n",
       "\u001b[32mthem in the latent space of powerful pretrained autoencoders. In\\ncontrast to previous work, training diffusion \u001b[0m\n",
       "\u001b[32mmodels on such a representation\\nallows for the first time to reach a near-optimal point between \u001b[0m\n",
       "\u001b[32mcomplexity\\nreduction and detail preservation, greatly boosting visual fidelity. By\\nintroducing cross-attention \u001b[0m\n",
       "\u001b[32mlayers into the model architecture, we turn\\ndiffusion models into powerful and flexible generators for general \u001b[0m\n",
       "\u001b[32mconditioning\\ninputs such as text or bounding boxes and high-resolution synthesis becomes\\npossible in a \u001b[0m\n",
       "\u001b[32mconvolutional manner. Our latent diffusion models \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLDMs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m achieve\\na new state of the art for image inpainting and \u001b[0m\n",
       "\u001b[32mhighly competitive performance\\non various tasks, including unconditional image generation, semantic \u001b[0m\n",
       "\u001b[32mscene\\nsynthesis, and super-resolution, while significantly reducing computational\\nrequirements compared to \u001b[0m\n",
       "\u001b[32mpixel-based DMs. Code is available at\\nhttps://github.com/CompVis/latent-diffusion .'\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document 8\n",
      " - # Chunks: 155\n",
      " - Metadata: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">{</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Published'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'2021-02-26'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Title'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Learning Transferable Visual Models From Natural Language Supervision'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Authors'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, Ilya Sutskever'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'Summary'</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'State-of-the-art computer vision systems are trained to predict a fixed set\\nof predetermined </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">object categories. This restricted form of supervision limits\\ntheir generality and usability since additional </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">labeled data is needed to\\nspecify any other visual concept. Learning directly from raw text about images\\nis a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">promising alternative which leverages a much broader source of\\nsupervision. We demonstrate that the simple </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">pre-training task of predicting\\nwhich caption goes with which image is an efficient and scalable way to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">learn\\nSOTA image representations from scratch on a dataset of 400 million (image,\\ntext) pairs collected from the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">internet. After pre-training, natural language\\nis used to reference learned visual concepts (or describe new ones)</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">enabling\\nzero-shot transfer of the model to downstream tasks. We study the performance\\nof this approach by </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">benchmarking on over 30 different existing computer vision\\ndatasets, spanning tasks such as OCR, action </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">recognition in videos,\\ngeo-localization, and many types of fine-grained object classification. The\\nmodel </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">transfers non-trivially to most tasks and is often competitive with a\\nfully supervised baseline without the need </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">for any dataset specific training.\\nFor instance, we match the accuracy of the original ResNet-50 on </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ImageNet\\nzero-shot without needing to use any of the 1.28 million training examples it\\nwas trained on. We release</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">our code and pre-trained model weights at\\nhttps://github.com/OpenAI/CLIP.'</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0m{\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Published'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'2021-02-26'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Title'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Learning Transferable Visual Models From Natural Language Supervision'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Authors'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish \u001b[0m\n",
       "\u001b[32mSastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, Ilya Sutskever'\u001b[0m\u001b[1;38;2;118;185;0m,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m    \u001b[0m\u001b[32m'Summary'\u001b[0m\u001b[1;38;2;118;185;0m: \u001b[0m\u001b[32m'State-of-the-art computer vision systems are trained to predict a fixed set\\nof predetermined \u001b[0m\n",
       "\u001b[32mobject categories. This restricted form of supervision limits\\ntheir generality and usability since additional \u001b[0m\n",
       "\u001b[32mlabeled data is needed to\\nspecify any other visual concept. Learning directly from raw text about images\\nis a \u001b[0m\n",
       "\u001b[32mpromising alternative which leverages a much broader source of\\nsupervision. We demonstrate that the simple \u001b[0m\n",
       "\u001b[32mpre-training task of predicting\\nwhich caption goes with which image is an efficient and scalable way to \u001b[0m\n",
       "\u001b[32mlearn\\nSOTA image representations from scratch on a dataset of 400 million \u001b[0m\u001b[32m(\u001b[0m\u001b[32mimage,\\ntext\u001b[0m\u001b[32m)\u001b[0m\u001b[32m pairs collected from the \u001b[0m\n",
       "\u001b[32minternet. After pre-training, natural language\\nis used to reference learned visual concepts \u001b[0m\u001b[32m(\u001b[0m\u001b[32mor describe new ones\u001b[0m\u001b[32m)\u001b[0m\n",
       "\u001b[32menabling\\nzero-shot transfer of the model to downstream tasks. We study the performance\\nof this approach by \u001b[0m\n",
       "\u001b[32mbenchmarking on over 30 different existing computer vision\\ndatasets, spanning tasks such as OCR, action \u001b[0m\n",
       "\u001b[32mrecognition in videos,\\ngeo-localization, and many types of fine-grained object classification. The\\nmodel \u001b[0m\n",
       "\u001b[32mtransfers non-trivially to most tasks and is often competitive with a\\nfully supervised baseline without the need \u001b[0m\n",
       "\u001b[32mfor any dataset specific training.\\nFor instance, we match the accuracy of the original ResNet-50 on \u001b[0m\n",
       "\u001b[32mImageNet\\nzero-shot without needing to use any of the 1.28 million training examples it\\nwas trained on. We release\u001b[0m\n",
       "\u001b[32mour code and pre-trained model weights at\\nhttps://github.com/OpenAI/CLIP.'\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import ArxivLoader\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=100,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \";\", \",\", \" \"],\n",
    ")\n",
    "\n",
    "print(\"Loading Documents\")\n",
    "docs = [\n",
    "    ArxivLoader(query=\"1706.03762\").load(),  ## Attention Is All You Need Paper\n",
    "    ArxivLoader(query=\"1810.04805\").load(),  ## BERT Paper\n",
    "    ArxivLoader(query=\"2005.11401\").load(),  ## RAG Paper\n",
    "    ArxivLoader(query=\"2205.00445\").load(),  ## MRKL Paper\n",
    "    ArxivLoader(query=\"2310.06825\").load(),  ## Mistral Paper\n",
    "    ArxivLoader(query=\"2306.05685\").load(),  ## LLM-as-a-Judge\n",
    "    ## Some longer papers\n",
    "    ArxivLoader(query=\"2210.03629\").load(),  ## ReAct Paper\n",
    "    ArxivLoader(query=\"2112.10752\").load(),  ## Latent Stable Diffusion Paper\n",
    "    ArxivLoader(query=\"2103.00020\").load(),  ## CLIP Paper\n",
    "]\n",
    "\n",
    "## Cut the paper short if references is included.\n",
    "## This is a standard string in papers.\n",
    "for doc in docs:\n",
    "    content = json.dumps(doc[0].page_content)\n",
    "    if \"References\" in content:\n",
    "        doc[0].page_content = content[:content.index(\"References\")]\n",
    "\n",
    "## Split the documents and also filter out stubs (overly short chunks)\n",
    "print(\"Chunking Documents\")\n",
    "docs_chunks = [text_splitter.split_documents(doc) for doc in docs]\n",
    "docs_chunks = [[c for c in dchunks if len(c.page_content) > 200] for dchunks in docs_chunks]\n",
    "\n",
    "## Make some custom Chunks to give big-picture details\n",
    "doc_string = \"Available Documents:\"\n",
    "doc_metadata = []\n",
    "for chunks in docs_chunks:\n",
    "    metadata = getattr(chunks[0], 'metadata', {})\n",
    "    doc_string += \"\\n - \" + metadata.get('Title')\n",
    "    doc_metadata += [str(metadata)]\n",
    "\n",
    "extra_chunks = [doc_string] + doc_metadata\n",
    "\n",
    "## Printing out some summary information for reference\n",
    "pprint(doc_string, '\\n')\n",
    "for i, chunks in enumerate(docs_chunks):\n",
    "    print(f\"Document {i}\")\n",
    "    print(f\" - # Chunks: {len(chunks)}\")\n",
    "    print(f\" - Metadata: \")\n",
    "    pprint(chunks[0].metadata)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c62359",
   "metadata": {},
   "source": [
    "### 4.2 Constructing Document Vector Stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "25a3c9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing Vector Stores\n",
      "CPU times: user 3.74 s, sys: 7min 18s, total: 7min 21s\n",
      "Wall time: 35min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Constructing Vector Stores\")\n",
    "vecstores = [FAISS.from_texts(extra_chunks, embedder)]\n",
    "vecstores += [FAISS.from_documents(doc_chunk, embedder) for doc_chunk in docs_chunks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597fc06e-367d-45bc-a5ee-0de8ee6441e7",
   "metadata": {},
   "source": [
    "Constructing Vector Stores\n",
    "CPU times: user 3.74 s, sys: 7min 18s, total: 7min 21s\n",
    "Wall time: 35min 46s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c740d708",
   "metadata": {},
   "outputs": [],
   "source": [
    "from faiss import IndexFlatL2\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "\n",
    "embed_dims = len(embedder.embed_query(\"test\"))\n",
    "def default_FAISS():\n",
    "    '''Useful utility for making an empty FAISS vectorstore'''\n",
    "    return FAISS(\n",
    "        embedding_function=embedder,\n",
    "        index=IndexFlatL2(embed_dims),\n",
    "        docstore=InMemoryDocstore(),\n",
    "        index_to_docstore_id={},\n",
    "        normalize_L2=False\n",
    "    )\n",
    "\n",
    "def aggregate_vstores(vectorstores):\n",
    "    ## Initialize an empty FAISS Index and merge others into it\n",
    "    ## We'll use default_faiss for simplicity, though it's tied to our embedder by reference\n",
    "    agg_vstore = default_FAISS()\n",
    "    for vstore in vectorstores:\n",
    "        agg_vstore.merge_from(vstore)\n",
    "    return agg_vstore\n",
    "\n",
    "## Unintuitive optimization; merge_from seems to optimize constituent vector stores away\n",
    "docstore = aggregate_vstores(vecstores)\n",
    "\n",
    "print(f\"Constructed aggregate docstore with {len(docstore.docstore._dict)} chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ab51e8-cb2f-41c9-b03c-f49873e07519",
   "metadata": {},
   "source": [
    "If you want to load pre-constructed docstore instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c85e6aff-cd0a-42ca-bfe1-7914b4815ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded aggregate docstore with 571 chunks\n"
     ]
    }
   ],
   "source": [
    "docstore = FAISS.load_local(\"docstore_index\", embedder, allow_dangerous_deserialization=True)\n",
    "print(f\"Loaded aggregate docstore with {len(docstore.docstore._dict)} chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc90255",
   "metadata": {},
   "source": [
    "### 4.3 Implementing RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "af854964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG, or Retrieval-Augmented Generation, is a method for answering questions using both a retriever and a generator.  Unlike some other approaches, it achieves state-of-the-art performance without needing expensive pre-training or extra components like a re-ranker or extractive reader [Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks].  It's advantageous because it can generate answers even if the exact answer isn't verbatim in the retrieved documents; it can synthesize information from multiple documents to create a correct response, something extractive methods can't do [Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks]. In fact, RAG can even generate correct answers even when the answer isn't in *any* of the retrieved documents [Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks].  There are two main variations: RAG-Token and RAG-Sequence, with the latter requiring a different decoding approach due to its likelihood calculation [Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks].  The retriever in RAG is initially set up using the DPR retriever, which relies on Natural Questions and TriviaQA data for training [Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks].  Finally,  RAG models generally produce more factual and specific answers, and show greater generation diversity than comparables like BART [Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks].\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.runnables.passthrough import RunnableAssign\n",
    "import gradio as gr\n",
    "from operator import itemgetter\n",
    "\n",
    "convstore = default_FAISS()\n",
    "\n",
    "def save_memory_and_get_output(d, vstore):\n",
    "    \"\"\"Accepts 'input'/'output' dictionary and saves to convstore\"\"\"\n",
    "    vstore.add_texts([\n",
    "        f\"User previously responded with {d.get('input')}\",\n",
    "        f\"Agent previously responded with {d.get('output')}\"\n",
    "    ])\n",
    "    return d.get('output')\n",
    "\n",
    "initial_msg = (\n",
    "    \"Hello! I am a document chat agent here to help the user!\"\n",
    "    f\" I have access to the following documents: {doc_string}\\n\\nHow can I help you?\"\n",
    ")\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_template(\"You are a document chatbot. Help the user as they ask questions about documents.\"\n",
    "    \" User messaged just asked: {input}\\n\\n\"\n",
    "    \" From this, we have retrieved the following potentially-useful info: \"\n",
    "    \" Conversation History Retrieval:\\n{history}\\n\\n\"\n",
    "    \" Document Retrieval:\\n{context}\\n\\n\"\n",
    "    \" (Answer only from retrieval. Only cite sources that are used. Make your response conversational.)\"\n",
    ")\n",
    "\n",
    "stream_chain = chat_prompt | instruct_llm | StrOutputParser()\n",
    "\n",
    "## Implementing the retrieval chain to make the system work\n",
    "\n",
    "retrieval_chain = (\n",
    "    {'input' : (lambda x: x)}\n",
    "    ## Retrieve history & context from convstore & docstore, respectively.\n",
    "    ## Our solution uses RunnableAssign, itemgetter, long_reorder, and docs2str\n",
    "    | RunnableAssign({'history': itemgetter('input') | convstore.as_retriever() | long_reorder | docs2str})\n",
    "    | RunnableAssign({'context': itemgetter('input') | docstore.as_retriever()  | long_reorder | docs2str})\n",
    ")\n",
    "\n",
    "def chat_gen(message, history=[], return_buffer=True):\n",
    "    buffer = \"\"\n",
    "    ## First perform the retrieval based on the input message\n",
    "    retrieval = retrieval_chain.invoke(message)\n",
    "    line_buffer = \"\"\n",
    "\n",
    "    ## Then, stream the results of the stream_chain\n",
    "    for token in stream_chain.stream(retrieval):\n",
    "        buffer += token\n",
    "        ## If you're using standard print, keep line from getting too long\n",
    "        yield buffer if return_buffer else token\n",
    "\n",
    "    ## Lastly, save the chat exchange to the conversation memory buffer\n",
    "    save_memory_and_get_output({'input':  message, 'output': buffer}, convstore)\n",
    "\n",
    "\n",
    "## Start of Agent Event Loop\n",
    "test_question = \"Tell me about RAG!\"\n",
    "\n",
    "## Before you launch your gradio interface, make sure your thing works\n",
    "for response in chat_gen(test_question, return_buffer=False):\n",
    "    print(response, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3794e88a",
   "metadata": {},
   "source": [
    "### 4.4 Gradio Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "80b74ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://b8adb8c80dc10192d6.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://b8adb8c80dc10192d6.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n",
      "Killing tunnel 127.0.0.1:7860 <> https://b8adb8c80dc10192d6.gradio.live\n",
      "Closing server running on port: 7860\n"
     ]
    }
   ],
   "source": [
    "mssg = {\"role\": \"user\", \"content\": initial_msg}\n",
    "chatbot = gr.Chatbot(value=[mssg], type='messages')\n",
    "demo = gr.ChatInterface(chat_gen, chatbot=chatbot, type='messages').queue()\n",
    "\n",
    "try:\n",
    "    demo.launch(debug=True, share=True, show_api=False)\n",
    "    demo.close()\n",
    "except Exception as e:\n",
    "    demo.close()\n",
    "    print(e)\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f605e5",
   "metadata": {},
   "source": [
    "### 4.5 Saving The Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9db4d90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a docstore_index\n",
      "a docstore_index/index.faiss\n",
      "a docstore_index/index.pkl\n"
     ]
    }
   ],
   "source": [
    "## Save and compress the index\n",
    "docstore.save_local(\"docstore_index\")\n",
    "!tar czvf docstore_index.tgz docstore_index\n",
    "\n",
    "# !rm -rf docstore_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7101a1df",
   "metadata": {},
   "source": [
    "### 4.6 Testing The Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4d084f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x docstore_index/\n",
      "x docstore_index/index.faiss\n",
      "x docstore_index/index.pkl\n",
      ".\\n\\u2022 Better characterizing biases in models, alerting other\\nresearchers to areas of concern and areas for interven-\\ntions.\\n\\u2022 Creating suites of tests to evaluate systems like CLIP\\non, so we can better characterize model capabilities\\nearlier in the development cycle.\\n\\u2022 Identifying potential failure modes and areas for further\\nwork.\\nWe plan to contribute to this work, and hope this analysis\\nprovides some motivating examples for subsequent research.\\n8. Related Work\\nAny model that leverages written, spoken, signed or any\\nother form of human language as part of its training signal\\nis arguably using natural language as a source of supervi-\\nsion. This is an admittedly extremely broad area and covers\\nmost work in the \\ufb01eld of distributional semantics including\\ntopic models (Blei et al., 2003), word, sentence, and para-\\ngraph vectors (Mikolov et al., 2013; Kiros et al., 2015; Le &\\nMikolov, 2014), and language models (Bengio et al., 2003)\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"False\"\n",
    "!tar xzvf docstore_index.tgz\n",
    "new_db = FAISS.load_local(\"docstore_index\", embedder, allow_dangerous_deserialization=True)\n",
    "testdocs = new_db.similarity_search(\"Testing\")\n",
    "print(testdocs[0].page_content[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fDDNaBA9N3XM",
   "metadata": {
    "id": "fDDNaBA9N3XM"
   },
   "source": [
    "## 5. Pairwise Evaluator\n",
    "\n",
    "The following is a custom implementation of a simplified [LangChain Pairwise String Evaluator](https://python.langchain.com/docs/guides/evaluation/examples/comparisons). \n",
    "\n",
    "**Preparing for RAG chain evaluation, we need to:**\n",
    "\n",
    "- Pull in the document index.\n",
    "- Recreate the RAG pipeline of choice.\n",
    "\n",
    "**Implementing a judge formulation as follows:**\n",
    "\n",
    "- Sample RAG agent document pool to find two document chunks.\n",
    "- Use those two document chunks to generate a synthetic \"baseline\" question-answer pair.\n",
    "- Use RAG agent to generate its own answer.\n",
    "- Use a judge LLM to compare the two responses while grounding the synthetic generation as \"ground-truth correct.\"\n",
    "\n",
    "The chain should be a simple but powerful process that that tests if the RAG chain outperforms a narrow chatbot with limited document access."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bh8jaOqak0f",
   "metadata": {
    "id": "1bh8jaOqak0f"
   },
   "source": [
    "### 5.1. Pulling In Document Retrieval Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "tlE7a2lseLOy",
   "metadata": {
    "id": "tlE7a2lseLOy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x docstore_index/\n",
      "x docstore_index/index.faiss\n",
      "x docstore_index/index.pkl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Constructed aggregate docstore with </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">571</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\"> chunks</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mConstructed aggregate docstore with \u001b[0m\u001b[1;36m571\u001b[0m\u001b[1;38;2;118;185;0m chunks\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Sample Chunk:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mSample Chunk:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paper: ReAct: Synergizing Reasoning and Acting in Language Models\n",
      "\n",
      "Summary: While large language models (LLMs) have demonstrated impressive capabilities\n",
      "across tasks in language understanding and interactive decision making, their\n",
      "abilities for reasoning (e.g. chain-of-thought prompting) and acting (e.g.\n",
      "action plan generation) have primarily been studied as separate topics. In this\n",
      "paper, we explore the use of LLMs to generate both reasoning traces and\n",
      "task-specific actions in an interleaved manner, allowing for greater synergy\n",
      "between the two: reasoning traces help the model induce, track, and update\n",
      "action plans as well as handle exceptions, while actions allow it to interface\n",
      "with external sources, such as knowledge bases or environments, to gather\n",
      "additional information. We apply our approach, named ReAct, to a diverse set of\n",
      "language and decision making tasks and demonstrate its effectiveness over\n",
      "state-of-the-art baselines, as well as improved human interpretability and\n",
      "trustworthiness over methods without reasoning or acting components.\n",
      "Concretely, on question answering (HotpotQA) and fact verification (Fever),\n",
      "ReAct overcomes issues of hallucination and error propagation prevalent in\n",
      "chain-of-thought reasoning by interacting with a simple Wikipedia API, and\n",
      "generates human-like task-solving trajectories that are more interpretable than\n",
      "baselines without reasoning traces. On two interactive decision making\n",
      "benchmarks (ALFWorld and WebShop), ReAct outperforms imitation and\n",
      "reinforcement learning methods by an absolute success rate of 34% and 10%\n",
      "respectively, while being prompted with only one or two in-context examples.\n",
      "Project site with code: https://react-lm.github.io\n",
      "\n",
      "Page Body: LLMs, language as a fundamental cognitive mechanism will play a critical role in interaction and decision making. What is more, progress in LLMs has also inspired the development of versatile and generalist agents like Reed et al. (2022). 6 CONCLUSION We have proposed ReAct – a simple yet effective method for synergizing reasoning and acting in large language models. Through a diverse set of experiments on multi-hop question-answering, fact checking, and interactive decision-making tasks, we show that ReAct leads to superior performance with interpretable decision traces. Despite the simplicity of our method, complex tasks with large action spaces require more demonstrations to learn well, which unfortunately can easily go beyond the input length limit of in-context learning. We explore the ﬁne-tuning approach on HotpotQA 6Human feedback can also be incorporated in a complementary manner but we leave it for future work. 9 Published as a conference paper at ICLR 2023\n"
     ]
    }
   ],
   "source": [
    "## Make sure docstore_index.tgz is in working directory\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# embedder = SentenceTransformersEmbeddings(model=\"Alibaba-NLP/gte-base-en-v1.5\")\n",
    "\n",
    "!tar xzvf docstore_index.tgz\n",
    "docstore = FAISS.load_local(\"docstore_index\", embedder, allow_dangerous_deserialization=True)\n",
    "docs = list(docstore.docstore._dict.values())\n",
    "\n",
    "def format_chunk(doc):\n",
    "    return (\n",
    "        f\"Paper: {doc.metadata.get('Title', 'unknown')}\"\n",
    "        f\"\\n\\nSummary: {doc.metadata.get('Summary', 'unknown')}\"\n",
    "        f\"\\n\\nPage Body: {doc.page_content.replace(\"\\n\", \" \")}\"\n",
    "    )\n",
    "\n",
    "## This printout just confirms that the store has been retrieved\n",
    "pprint(f\"Constructed aggregate docstore with {len(docstore.docstore._dict)} chunks\")\n",
    "pprint(f\"Sample Chunk:\")\n",
    "print(format_chunk(docs[len(docs)//2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dib0F-t2N4LJ",
   "metadata": {
    "id": "dib0F-t2N4LJ"
   },
   "source": [
    "### 5.2. Pulling In RAG Chain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "XBi6Y8b8aXd2",
   "metadata": {
    "id": "XBi6Y8b8aXd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:  Researchers are developing a new type of question-answering task using Jeopardy! clues as a benchmark.  Because Jeopardy! questions require concise, factual statements that cleverly conceal an answer, generating them is a challenging test of a large language model's knowledge and generation capabilities.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableBranch\n",
    "from operator import itemgetter\n",
    "\n",
    "embedder = SentenceTransformersEmbeddings(model=\"Alibaba-NLP/gte-base-en-v1.5\", trust_remote_code=True)\n",
    "\n",
    "instruct_llm = GeminiChat(model=\"gemini-1.5-flash\")\n",
    "\n",
    "llm = instruct_llm | StrOutputParser()\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_template(\n",
    "    \"{input}\"\n",
    "    \" Use the format:\\n\\nAnswer: (answer)\\n\\n\"\n",
    "    \"Document Retrieval:\\n{context}\\n\\n\"\n",
    "    \"Question Again: {input}\"\n",
    ")\n",
    "\n",
    "def output_puller(inputs):\n",
    "    \"\"\"\"Output generator. Useful if your chain returns a dictionary with key 'output'\"\"\"\n",
    "    if isinstance(inputs, dict):\n",
    "        inputs = [inputs]\n",
    "    for token in inputs:\n",
    "        if token.get('output'):\n",
    "            yield token.get('output')\n",
    "\n",
    "## Chain 1 Specs: \"Hello World\" -> retrieval_chain \n",
    "long_reorder = RunnableLambda(LongContextReorder().transform_documents)\n",
    "context_getter = itemgetter('input') | docstore.as_retriever() | long_reorder | docs2str\n",
    "retrieval_chain = {'input': (lambda x: x)} | RunnableAssign({'context': context_getter})\n",
    "\n",
    "## Chain 2 Specs: retrieval_chain -> generator_chain \n",
    "generator_chain = RunnableLambda(lambda x: RunnableAssign({'formatted_input': chat_prompt.invoke})) | RunnableLambda(lambda x: RunnableAssign({'output': RunnableLambda(lambda y: llm.invoke(y['formatted_input']))}))\n",
    "\n",
    "rag_chain = retrieval_chain | generator_chain\n",
    "\n",
    "## pprint(rag_chain.invoke(\"Tell me something interesting!\"))\n",
    "for token in [rag_chain.stream(\"Tell me something interesting!\")]:\n",
    "    for t in RunnableLambda(output_puller).invoke(token):\n",
    "        print(t, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b880971-d3a0-433f-a60b-e8a4edb754c8",
   "metadata": {},
   "source": [
    "### 5.3. Generating Synthetic Question-Answer Pairs\n",
    "\n",
    "Now we implement the first few part of our evaluation routine:\n",
    "\n",
    "- **Sample RAG agent document pool to find two document chunks.**\n",
    "- **Use those two document chunks to generate a synthetic \"baseline\" question-answer pair.**\n",
    "- Use RAG agent to generate its own answer.\n",
    "- Use a judge LLM to compare the two responses while grounding the synthetic generation as \"ground-truth correct.\"\n",
    "\n",
    "The chain should be a simple but powerful process that tests if the RAG chain outperforms a narrow chatbot with limited document access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "ymzuX-DSNvL6",
   "metadata": {
    "id": "ymzuX-DSNvL6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Q </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mQ \u001b[0m\u001b[1;36m1\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Question:  Considering the ReAct model's success in integrating reasoning and action, as exemplified by its ability</span>\n",
       "<span style=\"font-weight: bold\">to plan and execute actions like cleaning and placing a lettuce in the provided example, how might its interactive </span>\n",
       "<span style=\"font-weight: bold\">decision-making capabilities be further enhanced by incorporating more sophisticated environmental modeling and </span>\n",
       "<span style=\"font-weight: bold\">proactive planning beyond simple task completion?</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mQuestion:  Considering the ReAct model's success in integrating reasoning and action, as exemplified by its ability\u001b[0m\n",
       "\u001b[1mto plan and execute actions like cleaning and placing a lettuce in the provided example, how might its interactive \u001b[0m\n",
       "\u001b[1mdecision-making capabilities be further enhanced by incorporating more sophisticated environmental modeling and \u001b[0m\n",
       "\u001b[1mproactive planning beyond simple task completion?\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Q </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mQ \u001b[0m\u001b[1;36m2\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Question: Given the limitations of Large Language Models highlighted in the provided text, and the presented data </span>\n",
       "<span style=\"font-weight: bold\">on the performance of different mathematical formula structures within the MRKL system, how might the specific </span>\n",
       "<span style=\"font-weight: bold\">strengths and weaknesses of neuro-symbolic architectures like MRKL be leveraged to improve the accuracy and </span>\n",
       "<span style=\"font-weight: bold\">reliability of complex mathematical reasoning tasks in AI systems?</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mQuestion: Given the limitations of Large Language Models highlighted in the provided text, and the presented data \u001b[0m\n",
       "\u001b[1mon the performance of different mathematical formula structures within the MRKL system, how might the specific \u001b[0m\n",
       "\u001b[1mstrengths and weaknesses of neuro-symbolic architectures like MRKL be leveraged to improve the accuracy and \u001b[0m\n",
       "\u001b[1mreliability of complex mathematical reasoning tasks in AI systems?\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Q </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mQ \u001b[0m\u001b[1;36m3\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Question:  Given the ReAct model's demonstrated success in mitigating hallucination and error propagation in </span>\n",
       "<span style=\"font-weight: bold\">question answering and fact verification by interacting with a Wikipedia API, what novel applications could be </span>\n",
       "<span style=\"font-weight: bold\">explored by integrating ReAct with other external knowledge bases or APIs, and how might this impact the model's </span>\n",
       "<span style=\"font-weight: bold\">reasoning and action capabilities across diverse tasks?</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mQuestion:  Given the ReAct model's demonstrated success in mitigating hallucination and error propagation in \u001b[0m\n",
       "\u001b[1mquestion answering and fact verification by interacting with a Wikipedia API, what novel applications could be \u001b[0m\n",
       "\u001b[1mexplored by integrating ReAct with other external knowledge bases or APIs, and how might this impact the model's \u001b[0m\n",
       "\u001b[1mreasoning and action capabilities across diverse tasks?\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "num_questions = 3\n",
    "synth_questions = []\n",
    "synth_answers = []\n",
    "\n",
    "simple_prompt1 = ChatPromptTemplate.from_template('{system}\\n\\n{input}')\n",
    "\n",
    "for i in range(num_questions):\n",
    "    doc1 = random.sample(docs, 1)[0]\n",
    "    sys_msg = (\n",
    "        \"Use the documents provided to generate an interesting question.\"\n",
    "        \" Rely more on the document bodies than the summary.\"\n",
    "        \" Use the format:\\nQuestion: (good question, 1 sentence, detailed)\"\n",
    "    )\n",
    "    usr_msg = (\n",
    "        f\"Document: {format_chunk(doc1)}\"\n",
    "    )\n",
    "\n",
    "    q = (simple_prompt1 | llm).invoke({'system': sys_msg, 'input': usr_msg})\n",
    "    synth_questions += [q]\n",
    "    pprint2(f\"Q {i+1}\")\n",
    "    pprint2(synth_questions[-1])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "b71e74f6-527c-4ed9-8a95-8dd30d4cfdd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">A </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mA \u001b[0m\u001b[1;36m1\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Answer: Enhancing ReAct's interactive decision-making capabilities beyond simple task completion requires </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">incorporating more sophisticated environmental modeling and proactive planning. This could involve:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">) </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">**Developing richer world models:**  Instead of relying on limited, immediate sensory input, integrating external </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">knowledge bases, maps, or object-relationship graphs would allow ReAct to reason about the environment more </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">comprehensively. This would enable proactive actions like anticipating obstacles before they are encountered (e.g.,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">planning a route around a cluttered area before starting to clean). </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">) **Hierarchical planning:**  Moving beyond </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">flat sequences of actions, hierarchical planning would allow ReAct to break down complex tasks into sub-tasks, </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">enabling more robust and flexible planning.  This would allow for contingency planning –  if an unexpected event </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">occurs (e.g., the lettuce is unexpectedly slippery), the system can adapt its plan without restarting. </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">) </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">**Predictive modeling:**  Incorporating predictive models of the environment and the effects of actions would allow</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">ReAct to simulate potential outcomes and choose actions that maximize the likelihood of success. For example, </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">predicting the trajectory of a moving object to avoid collisions while navigating. </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">) **Reinforcement learning with</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">long-term rewards:**  Training the model with rewards that incentivize efficient and proactive behavior, extending </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">beyond immediate task completion, would encourage the system to develop more sophisticated planning skills.  For </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">example, rewarding efficient route planning or minimizing energy consumption. </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">) **Uncertainty handling:**  </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Incorporating probabilistic reasoning and uncertainty quantification would make the system more robust to noisy or </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">incomplete information about the environment. This would allow ReAct to handle situations where perfect information</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">is unavailable and plan accordingly.  By incorporating these advancements, ReAct could evolve from a simple task </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">executor to a proactive and adaptable agent capable of complex, long-term planning and decision-making in dynamic </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">environments.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mAnswer: Enhancing ReAct's interactive decision-making capabilities beyond simple task completion requires \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mincorporating more sophisticated environmental modeling and proactive planning. This could involve:  \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m \u001b[0m\n",
       "\u001b[1;38;2;118;185;0m**Developing richer world models:**  Instead of relying on limited, immediate sensory input, integrating external \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mknowledge bases, maps, or object-relationship graphs would allow ReAct to reason about the environment more \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mcomprehensively. This would enable proactive actions like anticipating obstacles before they are encountered \u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\u001b[1;38;2;118;185;0me.g.,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mplanning a route around a cluttered area before starting to clean\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m. \u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m **Hierarchical planning:**  Moving beyond \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mflat sequences of actions, hierarchical planning would allow ReAct to break down complex tasks into sub-tasks, \u001b[0m\n",
       "\u001b[1;38;2;118;185;0menabling more robust and flexible planning.  This would allow for contingency planning –  if an unexpected event \u001b[0m\n",
       "\u001b[1;38;2;118;185;0moccurs \u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\u001b[1;38;2;118;185;0me.g., the lettuce is unexpectedly slippery\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m, the system can adapt its plan without restarting. \u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m \u001b[0m\n",
       "\u001b[1;38;2;118;185;0m**Predictive modeling:**  Incorporating predictive models of the environment and the effects of actions would allow\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mReAct to simulate potential outcomes and choose actions that maximize the likelihood of success. For example, \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mpredicting the trajectory of a moving object to avoid collisions while navigating. \u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m **Reinforcement learning with\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mlong-term rewards:**  Training the model with rewards that incentivize efficient and proactive behavior, extending \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mbeyond immediate task completion, would encourage the system to develop more sophisticated planning skills.  For \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mexample, rewarding efficient route planning or minimizing energy consumption. \u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m **Uncertainty handling:**  \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mIncorporating probabilistic reasoning and uncertainty quantification would make the system more robust to noisy or \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mincomplete information about the environment. This would allow ReAct to handle situations where perfect information\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mis unavailable and plan accordingly.  By incorporating these advancements, ReAct could evolve from a simple task \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mexecutor to a proactive and adaptable agent capable of complex, long-term planning and decision-making in dynamic \u001b[0m\n",
       "\u001b[1;38;2;118;185;0menvironments.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">A </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mA \u001b[0m\u001b[1;36m2\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Answer:  Neuro-symbolic architectures like MRKL, by combining the strengths of neural networks (pattern </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">recognition, generalization) and symbolic AI (explicit knowledge representation, logical reasoning), can mitigate </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">the limitations of LLMs in complex mathematical reasoning.  The data on MRKL's performance with different formula </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">structures highlights the importance of carefully designing the symbolic component to represent mathematical </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">knowledge effectively.  To improve accuracy and reliability, we can leverage MRKL's strengths as follows:</span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">. **Improved Knowledge Representation:**  Use MRKL's symbolic reasoning capabilities to explicitly encode </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">mathematical axioms, theorems, and rules of inference.  This addresses LLMs' weakness in lacking explicit </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">understanding of mathematical concepts and relying on statistical correlations.  Analyzing the MRKL data to </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">identify optimal formula structures for encoding different mathematical domains would be crucial.</span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">. **Hybrid Approach:**  Combine the neural network's capacity for learning complex patterns with the symbolic </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">system's ability to perform deductive reasoning. The neural network can be trained on large datasets to learn </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">approximations and heuristic strategies, while the symbolic component ensures correctness and consistency. This </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">allows leveraging the strengths of both while minimizing their individual weaknesses.</span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">. **Explainability and Interpretability:**  The symbolic representation in MRKL allows for tracing the reasoning </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">steps, providing explainability absent in purely neural network approaches.  This interpretability is crucial for </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">debugging errors and building trust in the AI's mathematical conclusions.  Analyzing where MRKL falters (as </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">revealed by the performance data) can guide the improvement of both symbolic representations and the integration </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">with the neural component.</span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">. **Targeted Training:** Instead of relying on large-scale general training, focus on targeted training of the </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">neural components of MRKL on specific sub-problems or mathematical domains, informed by the performance data on </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">formula structures. This refined training can improve accuracy and address the limitations identified in the </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">specific mathematical formula types.</span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">. **Iterative Refinement:** Use the performance data on MRKL as feedback to iteratively refine both the symbolic </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">knowledge base and the neural network's architecture and training methodology. This continuous improvement cycle is</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">key to addressing the limitations of both approaches and maximizing the combined strengths.</span>\n",
       "\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">In essence, a well-designed neuro-symbolic system like MRKL can create a robust and reliable AI system for complex </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">mathematical reasoning by leveraging its capacity for both learning and logical deduction, provided that the </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">symbolic component is carefully designed and the interaction between symbolic and neural components is optimized, </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">informed by data-driven insights.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mAnswer:  Neuro-symbolic architectures like MRKL, by combining the strengths of neural networks \u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\u001b[1;38;2;118;185;0mpattern \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mrecognition, generalization\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m and symbolic AI \u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\u001b[1;38;2;118;185;0mexplicit knowledge representation, logical reasoning\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m, can mitigate \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mthe limitations of LLMs in complex mathematical reasoning.  The data on MRKL's performance with different formula \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mstructures highlights the importance of carefully designing the symbolic component to represent mathematical \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mknowledge effectively.  To improve accuracy and reliability, we can leverage MRKL's strengths as follows:\u001b[0m\n",
       "\n",
       "\u001b[1;36m1\u001b[0m\u001b[1;38;2;118;185;0m. **Improved Knowledge Representation:**  Use MRKL's symbolic reasoning capabilities to explicitly encode \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mmathematical axioms, theorems, and rules of inference.  This addresses LLMs' weakness in lacking explicit \u001b[0m\n",
       "\u001b[1;38;2;118;185;0munderstanding of mathematical concepts and relying on statistical correlations.  Analyzing the MRKL data to \u001b[0m\n",
       "\u001b[1;38;2;118;185;0midentify optimal formula structures for encoding different mathematical domains would be crucial.\u001b[0m\n",
       "\n",
       "\u001b[1;36m2\u001b[0m\u001b[1;38;2;118;185;0m. **Hybrid Approach:**  Combine the neural network's capacity for learning complex patterns with the symbolic \u001b[0m\n",
       "\u001b[1;38;2;118;185;0msystem's ability to perform deductive reasoning. The neural network can be trained on large datasets to learn \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mapproximations and heuristic strategies, while the symbolic component ensures correctness and consistency. This \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mallows leveraging the strengths of both while minimizing their individual weaknesses.\u001b[0m\n",
       "\n",
       "\u001b[1;36m3\u001b[0m\u001b[1;38;2;118;185;0m. **Explainability and Interpretability:**  The symbolic representation in MRKL allows for tracing the reasoning \u001b[0m\n",
       "\u001b[1;38;2;118;185;0msteps, providing explainability absent in purely neural network approaches.  This interpretability is crucial for \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mdebugging errors and building trust in the AI's mathematical conclusions.  Analyzing where MRKL falters \u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\u001b[1;38;2;118;185;0mas \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mrevealed by the performance data\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m can guide the improvement of both symbolic representations and the integration \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mwith the neural component.\u001b[0m\n",
       "\n",
       "\u001b[1;36m4\u001b[0m\u001b[1;38;2;118;185;0m. **Targeted Training:** Instead of relying on large-scale general training, focus on targeted training of the \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mneural components of MRKL on specific sub-problems or mathematical domains, informed by the performance data on \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mformula structures. This refined training can improve accuracy and address the limitations identified in the \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mspecific mathematical formula types.\u001b[0m\n",
       "\n",
       "\u001b[1;36m5\u001b[0m\u001b[1;38;2;118;185;0m. **Iterative Refinement:** Use the performance data on MRKL as feedback to iteratively refine both the symbolic \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mknowledge base and the neural network's architecture and training methodology. This continuous improvement cycle is\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mkey to addressing the limitations of both approaches and maximizing the combined strengths.\u001b[0m\n",
       "\n",
       "\n",
       "\u001b[1;38;2;118;185;0mIn essence, a well-designed neuro-symbolic system like MRKL can create a robust and reliable AI system for complex \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mmathematical reasoning by leveraging its capacity for both learning and logical deduction, provided that the \u001b[0m\n",
       "\u001b[1;38;2;118;185;0msymbolic component is carefully designed and the interaction between symbolic and neural components is optimized, \u001b[0m\n",
       "\u001b[1;38;2;118;185;0minformed by data-driven insights.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">A </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mA \u001b[0m\u001b[1;36m3\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Answer: Integrating ReAct with other external knowledge bases and APIs beyond Wikipedia could unlock numerous novel</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">applications and significantly enhance its reasoning and action capabilities.  Here are some examples:</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">**Novel Applications:**</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">* **Scientific Discovery and Hypothesis Generation:**  ReAct could be integrated with scientific databases like </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">PubMed, Reaxys, or arXiv.  This would allow it to formulate hypotheses, design experiments, and interpret results </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">by referencing relevant literature and data, potentially accelerating scientific breakthroughs.  The model could </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">reason about complex biological pathways, chemical reactions, or astronomical phenomena by accessing and processing</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">information from these specialized sources.</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">* **Financial Modeling and Risk Assessment:** Combining ReAct with financial APIs (e.g., accessing real-time market</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">data, company financials, economic indicators) could enable sophisticated financial modeling, risk assessment, and </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">investment strategy generation. The model could analyze market trends, predict future performance, and make </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">informed investment decisions based on the data it retrieves and processes.</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">* **Personalized Healthcare and Medical Diagnosis Support:**  Integrating ReAct with Electronic Health Records </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(EHR) systems and medical knowledge bases could assist doctors in diagnosis and treatment planning.  The model </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">could analyze patient data, identify potential diagnoses, suggest relevant treatments, and even anticipate </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">potential complications based on its access to medical literature and patient histories. However, ethical </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">considerations regarding patient privacy and data security would need careful attention.</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">* **Legal Research and Due Diligence:**  Access to legal databases (e.g., Westlaw, LexisNexis) would allow ReAct to</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">perform legal research, identify relevant case law, and assist in due diligence processes. This could significantly</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">streamline legal workflows and improve the accuracy of legal advice.</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">* **Supply Chain Optimization and Logistics:**  Integration with real-time logistics and supply chain data APIs </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">could allow ReAct to optimize inventory management, predict disruptions, and suggest efficient routing strategies. </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">This could lead to cost savings and increased efficiency in supply chains.</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">**Impact on Reasoning and Action Capabilities:**</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Integrating ReAct with diverse external knowledge bases would:</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">* **Expand its knowledge domain:**  ReAct's capabilities would no longer be limited to the information available </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">within Wikipedia.  It could access and process information from specialized domains, significantly broadening its </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">scope.</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">* **Improve reasoning accuracy:**  Access to more comprehensive and up-to-date information would reduce </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">hallucination and improve the accuracy of its reasoning and conclusions.</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">* **Enable more complex reasoning tasks:**  The ability to interact with multiple data sources would allow ReAct to</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">perform more complex reasoning tasks that require synthesizing information from diverse sources.</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">* **Enhance action capabilities:** The model's ability to directly interact with and manipulate external systems </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(e.g., making API calls to update databases, trigger actions in a robotic system) would enable more sophisticated </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">actions.</span>\n",
       "\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">However, challenges remain: ensuring data quality, managing API rate limits, dealing with conflicting information </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">from different sources, and addressing potential biases in the data accessed are crucial considerations for </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">successful integration.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mAnswer: Integrating ReAct with other external knowledge bases and APIs beyond Wikipedia could unlock numerous novel\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mapplications and significantly enhance its reasoning and action capabilities.  Here are some examples:\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0m**Novel Applications:**\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0m* **Scientific Discovery and Hypothesis Generation:**  ReAct could be integrated with scientific databases like \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mPubMed, Reaxys, or arXiv.  This would allow it to formulate hypotheses, design experiments, and interpret results \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mby referencing relevant literature and data, potentially accelerating scientific breakthroughs.  The model could \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mreason about complex biological pathways, chemical reactions, or astronomical phenomena by accessing and processing\u001b[0m\n",
       "\u001b[1;38;2;118;185;0minformation from these specialized sources.\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0m* **Financial Modeling and Risk Assessment:** Combining ReAct with financial APIs \u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\u001b[1;38;2;118;185;0me.g., accessing real-time market\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mdata, company financials, economic indicators\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m could enable sophisticated financial modeling, risk assessment, and \u001b[0m\n",
       "\u001b[1;38;2;118;185;0minvestment strategy generation. The model could analyze market trends, predict future performance, and make \u001b[0m\n",
       "\u001b[1;38;2;118;185;0minformed investment decisions based on the data it retrieves and processes.\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0m* **Personalized Healthcare and Medical Diagnosis Support:**  Integrating ReAct with Electronic Health Records \u001b[0m\n",
       "\u001b[1;38;2;118;185;0m(\u001b[0m\u001b[1;38;2;118;185;0mEHR\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m systems and medical knowledge bases could assist doctors in diagnosis and treatment planning.  The model \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mcould analyze patient data, identify potential diagnoses, suggest relevant treatments, and even anticipate \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mpotential complications based on its access to medical literature and patient histories. However, ethical \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mconsiderations regarding patient privacy and data security would need careful attention.\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0m* **Legal Research and Due Diligence:**  Access to legal databases \u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\u001b[1;38;2;118;185;0me.g., Westlaw, LexisNexis\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m would allow ReAct to\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mperform legal research, identify relevant case law, and assist in due diligence processes. This could significantly\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mstreamline legal workflows and improve the accuracy of legal advice.\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0m* **Supply Chain Optimization and Logistics:**  Integration with real-time logistics and supply chain data APIs \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mcould allow ReAct to optimize inventory management, predict disruptions, and suggest efficient routing strategies. \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mThis could lead to cost savings and increased efficiency in supply chains.\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0m**Impact on Reasoning and Action Capabilities:**\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0mIntegrating ReAct with diverse external knowledge bases would:\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0m* **Expand its knowledge domain:**  ReAct's capabilities would no longer be limited to the information available \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mwithin Wikipedia.  It could access and process information from specialized domains, significantly broadening its \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mscope.\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m* **Improve reasoning accuracy:**  Access to more comprehensive and up-to-date information would reduce \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mhallucination and improve the accuracy of its reasoning and conclusions.\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m* **Enable more complex reasoning tasks:**  The ability to interact with multiple data sources would allow ReAct to\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mperform more complex reasoning tasks that require synthesizing information from diverse sources.\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m* **Enhance action capabilities:** The model's ability to directly interact with and manipulate external systems \u001b[0m\n",
       "\u001b[1;38;2;118;185;0m(\u001b[0m\u001b[1;38;2;118;185;0me.g., making API calls to update databases, trigger actions in a robotic system\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m would enable more sophisticated \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mactions.\u001b[0m\n",
       "\n",
       "\n",
       "\u001b[1;38;2;118;185;0mHowever, challenges remain: ensuring data quality, managing API rate limits, dealing with conflicting information \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mfrom different sources, and addressing potential biases in the data accessed are crucial considerations for \u001b[0m\n",
       "\u001b[1;38;2;118;185;0msuccessful integration.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "synth_answers = []\n",
    "\n",
    "simple_prompt2 = ChatPromptTemplate.from_template('{input} {system}')\n",
    "\n",
    "for i in range(num_questions):\n",
    "    sys_msg = (\n",
    "        \" Use the format: \\\"Answer: (answer)\\\"\"\n",
    "    )\n",
    "    a = (simple_prompt2 | llm).invoke({'system': sys_msg, 'input': synth_questions[i]})\n",
    "    synth_answers += [a]\n",
    "    pprint2(f\"A {i+1}\")\n",
    "    pprint(synth_answers[-1])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5Q-3X4vS98P",
   "metadata": {
    "id": "c5Q-3X4vS98P"
   },
   "source": [
    "### 5.4. Answer The Synthetic Questions\n",
    "\n",
    "Now we implement the third part of our evaluation routine:\n",
    "\n",
    "- Sample RAG agent document pool to find two document chunks.\n",
    "- Use those two document chunks to generate a synthetic \"baseline\" question-answer pair.\n",
    "- **Use RAG agent to generate its own answer.**\n",
    "- Use a judge LLM to compare the two responses while grounding the synthetic generation as \"ground-truth correct.\"\n",
    "\n",
    "The chain should be a simple but powerful process that tests if the RAG chain outperforms a narrow chatbot with limited document access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "7T3GSwhZPHjF",
   "metadata": {
    "id": "7T3GSwhZPHjF"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Q </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "\n",
       "<span style=\"font-weight: bold\">Question:  Considering the ReAct model's success in integrating reasoning and action, as exemplified by its ability</span>\n",
       "<span style=\"font-weight: bold\">to plan and execute actions like cleaning and placing a lettuce in the provided example, how might its interactive </span>\n",
       "<span style=\"font-weight: bold\">decision-making capabilities be further enhanced by incorporating more sophisticated environmental modeling and </span>\n",
       "<span style=\"font-weight: bold\">proactive planning beyond simple task completion?</span>\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mQ \u001b[0m\u001b[1;36m1\u001b[0m\n",
       "\n",
       "\u001b[1mQuestion:  Considering the ReAct model's success in integrating reasoning and action, as exemplified by its ability\u001b[0m\n",
       "\u001b[1mto plan and execute actions like cleaning and placing a lettuce in the provided example, how might its interactive \u001b[0m\n",
       "\u001b[1mdecision-making capabilities be further enhanced by incorporating more sophisticated environmental modeling and \u001b[0m\n",
       "\u001b[1mproactive planning beyond simple task completion?\u001b[0m\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">RAG Answer: </span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Answer: Enhancing ReAct's interactive decision-making capabilities beyond simple task completion requires </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">incorporating more sophisticated environmental modeling and proactive planning.  This could involve:</span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">. **Developing richer internal representations of the environment:**  Instead of relying on simple descriptions, </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">ReAct could benefit from integrating more detailed, structured environmental models. This might involve using </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">graph-based representations to capture object relationships, spatial layouts, and potential interactions.  This </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">would allow for more complex reasoning about the consequences of actions and more robust planning.</span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">. **Implementing proactive planning mechanisms:** Currently, ReAct's planning seems largely reactive.  More </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">sophisticated planning algorithms, such as Monte Carlo Tree Search (MCTS) or hierarchical planning, could be </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">incorporated to explore potential action sequences and evaluate their expected outcomes before execution.  This </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">proactive approach would enable anticipation of future needs and potential obstacles, leading to more efficient and</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">robust task completion.</span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">. **Integrating temporal reasoning:**  Adding temporal reasoning capabilities would allow ReAct to consider the </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">timing of actions and their dependencies. For instance, understanding that cleaning the lettuce must precede </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">placing it on the table is a simple example; more complex scenarios may require sophisticated scheduling and </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">resource management.</span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">. **Incorporating uncertainty and risk assessment:**  Real-world environments are inherently uncertain.  </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Augmenting ReAct with probabilistic models and risk assessment mechanisms would allow it to handle unexpected </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">events and make more robust decisions under uncertainty. For example, it could plan for alternative actions if a </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">required object is unavailable.</span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">. **Leveraging external knowledge bases:**  Integrating access to broader knowledge bases beyond simple APIs could</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">provide ReAct with more context and information for planning.  This could include knowledge about object </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">properties, typical action sequences, or potential hazards.</span>\n",
       "\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">By integrating these enhancements, ReAct could move beyond simple task completion towards more complex, adaptive, </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">and proactive interaction with the environment.  It would then be able to handle unforeseen circumstances, plan for</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">contingencies, and optimize its actions for efficiency and robustness.</span>\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mRAG Answer: \u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0mAnswer: Enhancing ReAct's interactive decision-making capabilities beyond simple task completion requires \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mincorporating more sophisticated environmental modeling and proactive planning.  This could involve:\u001b[0m\n",
       "\n",
       "\u001b[1;36m1\u001b[0m\u001b[1;38;2;118;185;0m. **Developing richer internal representations of the environment:**  Instead of relying on simple descriptions, \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mReAct could benefit from integrating more detailed, structured environmental models. This might involve using \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mgraph-based representations to capture object relationships, spatial layouts, and potential interactions.  This \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mwould allow for more complex reasoning about the consequences of actions and more robust planning.\u001b[0m\n",
       "\n",
       "\u001b[1;36m2\u001b[0m\u001b[1;38;2;118;185;0m. **Implementing proactive planning mechanisms:** Currently, ReAct's planning seems largely reactive.  More \u001b[0m\n",
       "\u001b[1;38;2;118;185;0msophisticated planning algorithms, such as Monte Carlo Tree Search \u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\u001b[1;38;2;118;185;0mMCTS\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m or hierarchical planning, could be \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mincorporated to explore potential action sequences and evaluate their expected outcomes before execution.  This \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mproactive approach would enable anticipation of future needs and potential obstacles, leading to more efficient and\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mrobust task completion.\u001b[0m\n",
       "\n",
       "\u001b[1;36m3\u001b[0m\u001b[1;38;2;118;185;0m. **Integrating temporal reasoning:**  Adding temporal reasoning capabilities would allow ReAct to consider the \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mtiming of actions and their dependencies. For instance, understanding that cleaning the lettuce must precede \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mplacing it on the table is a simple example; more complex scenarios may require sophisticated scheduling and \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mresource management.\u001b[0m\n",
       "\n",
       "\u001b[1;36m4\u001b[0m\u001b[1;38;2;118;185;0m. **Incorporating uncertainty and risk assessment:**  Real-world environments are inherently uncertain.  \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mAugmenting ReAct with probabilistic models and risk assessment mechanisms would allow it to handle unexpected \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mevents and make more robust decisions under uncertainty. For example, it could plan for alternative actions if a \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mrequired object is unavailable.\u001b[0m\n",
       "\n",
       "\u001b[1;36m5\u001b[0m\u001b[1;38;2;118;185;0m. **Leveraging external knowledge bases:**  Integrating access to broader knowledge bases beyond simple APIs could\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mprovide ReAct with more context and information for planning.  This could include knowledge about object \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mproperties, typical action sequences, or potential hazards.\u001b[0m\n",
       "\n",
       "\n",
       "\u001b[1;38;2;118;185;0mBy integrating these enhancements, ReAct could move beyond simple task completion towards more complex, adaptive, \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mand proactive interaction with the environment.  It would then be able to handle unforeseen circumstances, plan for\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mcontingencies, and optimize its actions for efficiency and robustness.\u001b[0m\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Q </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "\n",
       "<span style=\"font-weight: bold\">Question: Given the limitations of Large Language Models highlighted in the provided text, and the presented data </span>\n",
       "<span style=\"font-weight: bold\">on the performance of different mathematical formula structures within the MRKL system, how might the specific </span>\n",
       "<span style=\"font-weight: bold\">strengths and weaknesses of neuro-symbolic architectures like MRKL be leveraged to improve the accuracy and </span>\n",
       "<span style=\"font-weight: bold\">reliability of complex mathematical reasoning tasks in AI systems?</span>\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mQ \u001b[0m\u001b[1;36m2\u001b[0m\n",
       "\n",
       "\u001b[1mQuestion: Given the limitations of Large Language Models highlighted in the provided text, and the presented data \u001b[0m\n",
       "\u001b[1mon the performance of different mathematical formula structures within the MRKL system, how might the specific \u001b[0m\n",
       "\u001b[1mstrengths and weaknesses of neuro-symbolic architectures like MRKL be leveraged to improve the accuracy and \u001b[0m\n",
       "\u001b[1mreliability of complex mathematical reasoning tasks in AI systems?\u001b[0m\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">RAG Answer: </span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Answer: The provided text highlights limitations of Large Language Models (LLMs), such as a lack of access to </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">current/proprietary information and an inability to reason symbolically.  MRKL, a neuro-symbolic architecture, </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">addresses these weaknesses by combining LLMs with external knowledge sources and discrete reasoning modules.  To </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">improve accuracy and reliability in complex mathematical reasoning, MRKL's strengths can be leveraged as follows:</span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">. **Symbolic Reasoning for Precise Calculations:**  LLMs excel at natural language processing but struggle with </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">precise, symbolic manipulation needed for complex mathematics.  MRKL's discrete reasoning modules can handle this, </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">ensuring accurate execution of mathematical formulas and algorithms regardless of their complexity or the need for </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">specialized knowledge.  The system can translate natural language problem statements into symbolic representations,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">allowing the reasoning module to perform calculations, and then translate the result back into natural language.</span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">. **Knowledge Integration for Contextual Understanding:**  LLMs may lack access to specific data or formulas </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">necessary for advanced mathematical tasks.  MRKL's integration of external knowledge sources (databases, </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">specialized libraries, etc.) provides access to this information, enabling the system to correctly interpret the </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">context of a problem and select the appropriate formulas and data.</span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">. **Modular Design for Flexibility and Scalability:** The modular design of MRKL allows for the addition of new </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">knowledge modules and reasoning capabilities as needed. This flexibility makes it adaptable to various mathematical</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">domains and facilitates easier expansion for tackling more intricate problems.</span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">. **Hybrid Approach for Enhanced Performance:**  MRKL's combination of LLMs and symbolic reasoning creates a </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">synergistic effect. LLMs can be used for initial problem understanding, formula extraction from textual </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">descriptions, and final result interpretation, while the symbolic modules handle the computationally intensive </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">parts.</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">However, challenges remain. The text mentions difficulties in intelligently routing inputs between modules and </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">avoiding model explosion.  Future development of MRKL should focus on optimizing these aspects to improve </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">efficiency and scalability for even more complex mathematical problems.  Furthermore, careful consideration needs </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">to be given to the selection and integration of external knowledge sources to ensure accuracy and reliability of </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">the information used.</span>\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mRAG Answer: \u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0mAnswer: The provided text highlights limitations of Large Language Models \u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\u001b[1;38;2;118;185;0mLLMs\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m, such as a lack of access to \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mcurrent/proprietary information and an inability to reason symbolically.  MRKL, a neuro-symbolic architecture, \u001b[0m\n",
       "\u001b[1;38;2;118;185;0maddresses these weaknesses by combining LLMs with external knowledge sources and discrete reasoning modules.  To \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mimprove accuracy and reliability in complex mathematical reasoning, MRKL's strengths can be leveraged as follows:\u001b[0m\n",
       "\n",
       "\u001b[1;36m1\u001b[0m\u001b[1;38;2;118;185;0m. **Symbolic Reasoning for Precise Calculations:**  LLMs excel at natural language processing but struggle with \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mprecise, symbolic manipulation needed for complex mathematics.  MRKL's discrete reasoning modules can handle this, \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mensuring accurate execution of mathematical formulas and algorithms regardless of their complexity or the need for \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mspecialized knowledge.  The system can translate natural language problem statements into symbolic representations,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mallowing the reasoning module to perform calculations, and then translate the result back into natural language.\u001b[0m\n",
       "\n",
       "\u001b[1;36m2\u001b[0m\u001b[1;38;2;118;185;0m. **Knowledge Integration for Contextual Understanding:**  LLMs may lack access to specific data or formulas \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mnecessary for advanced mathematical tasks.  MRKL's integration of external knowledge sources \u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\u001b[1;38;2;118;185;0mdatabases, \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mspecialized libraries, etc.\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m provides access to this information, enabling the system to correctly interpret the \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mcontext of a problem and select the appropriate formulas and data.\u001b[0m\n",
       "\n",
       "\u001b[1;36m3\u001b[0m\u001b[1;38;2;118;185;0m. **Modular Design for Flexibility and Scalability:** The modular design of MRKL allows for the addition of new \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mknowledge modules and reasoning capabilities as needed. This flexibility makes it adaptable to various mathematical\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mdomains and facilitates easier expansion for tackling more intricate problems.\u001b[0m\n",
       "\n",
       "\u001b[1;36m4\u001b[0m\u001b[1;38;2;118;185;0m. **Hybrid Approach for Enhanced Performance:**  MRKL's combination of LLMs and symbolic reasoning creates a \u001b[0m\n",
       "\u001b[1;38;2;118;185;0msynergistic effect. LLMs can be used for initial problem understanding, formula extraction from textual \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mdescriptions, and final result interpretation, while the symbolic modules handle the computationally intensive \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mparts.\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0mHowever, challenges remain. The text mentions difficulties in intelligently routing inputs between modules and \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mavoiding model explosion.  Future development of MRKL should focus on optimizing these aspects to improve \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mefficiency and scalability for even more complex mathematical problems.  Furthermore, careful consideration needs \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mto be given to the selection and integration of external knowledge sources to ensure accuracy and reliability of \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mthe information used.\u001b[0m\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Q </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>\n",
       "\n",
       "<span style=\"font-weight: bold\">Question:  Given the ReAct model's demonstrated success in mitigating hallucination and error propagation in </span>\n",
       "<span style=\"font-weight: bold\">question answering and fact verification by interacting with a Wikipedia API, what novel applications could be </span>\n",
       "<span style=\"font-weight: bold\">explored by integrating ReAct with other external knowledge bases or APIs, and how might this impact the model's </span>\n",
       "<span style=\"font-weight: bold\">reasoning and action capabilities across diverse tasks?</span>\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mQ \u001b[0m\u001b[1;36m3\u001b[0m\n",
       "\n",
       "\u001b[1mQuestion:  Given the ReAct model's demonstrated success in mitigating hallucination and error propagation in \u001b[0m\n",
       "\u001b[1mquestion answering and fact verification by interacting with a Wikipedia API, what novel applications could be \u001b[0m\n",
       "\u001b[1mexplored by integrating ReAct with other external knowledge bases or APIs, and how might this impact the model's \u001b[0m\n",
       "\u001b[1mreasoning and action capabilities across diverse tasks?\u001b[0m\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">RAG Answer: </span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Answer: Integrating ReAct with various external knowledge bases and APIs beyond Wikipedia could unlock numerous </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">novel applications and significantly enhance its reasoning and action capabilities across diverse tasks.  The key </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">is ReAct's ability to synergistically combine reasoning and action, allowing it to iteratively refine its </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">understanding and actions based on external feedback.</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Here are some examples:</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">**</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">.  Scientific Literature Retrieval and Reasoning:**  Integrating ReAct with APIs for scientific databases like </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">PubMed, Semantic Scholar, or arXiv could enable the model to answer complex scientific questions requiring </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">multi-step reasoning across multiple papers.  This would allow for more accurate and nuanced answers than current </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">LLMs, which often hallucinate facts or misinterpret scientific findings.  The impact on reasoning would be a more </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">robust and evidence-based approach, and the action capability would extend to retrieving and synthesizing </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">information from disparate sources.</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">**</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">.  Financial Market Analysis and Prediction:**  Connecting ReAct to financial data APIs (e.g., Alpha Vantage, </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Tiingo) would enable sophisticated financial analysis.  The model could reason through complex market trends, </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">analyze company performance, and even formulate potential investment strategies by accessing and interpreting </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">real-time market data. Reasoning would become more data-driven and precise, while actions would involve querying </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">APIs for specific data points and formulating trades (in a simulated environment initially).</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">**</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">.  Legal Research and Argumentation:**  Integration with legal databases like Westlaw or LexisNexis would </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">revolutionize legal research.  ReAct could analyze case law, statutes, and regulations to provide accurate and </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">comprehensive legal opinions.  The reasoning capabilities would improve by utilizing precise legal language and </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">precedents, while actions would include retrieving relevant legal documents and constructing logical legal </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">arguments.</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">**</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">.  Medical Diagnosis and Treatment Planning (Simulated Environment):**  Within a simulated environment (crucial </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">for safety), ReAct could be integrated with medical knowledge bases and imaging APIs.  This could assist medical </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">professionals by analyzing patient data, suggesting potential diagnoses, and even outlining possible treatment </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">plans.  Reasoning would involve complex medical knowledge integration and risk assessment, while actions could </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">involve querying medical databases and creating treatment plans.  Ethical considerations and validation would be </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">paramount in any real-world application.</span>\n",
       "\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">**</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">.  Personalized Education and Tutoring:**  By connecting ReAct to educational APIs and databases, personalized </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">learning experiences could be created.  The model could adapt its teaching style to individual student needs, </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">provide targeted feedback, and generate custom learning materials.  Reasoning would involve understanding the </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">student's knowledge gaps and tailoring lessons accordingly, while actions would include selecting relevant learning</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">resources and providing personalized feedback.</span>\n",
       "\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">In all these examples, the impact on ReAct's capabilities would be significant.  The iterative process of reasoning</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">and acting, guided by external information, would mitigate hallucination, improve accuracy, and produce more robust</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">and explainable outputs. The ability to handle complex, multi-step reasoning tasks across diverse domains would be </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">significantly enhanced.  However, careful consideration of ethical implications, bias in data sources, and the </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">potential for misuse remains crucial for any real-world deployment.</span>\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mRAG Answer: \u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0mAnswer: Integrating ReAct with various external knowledge bases and APIs beyond Wikipedia could unlock numerous \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mnovel applications and significantly enhance its reasoning and action capabilities across diverse tasks.  The key \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mis ReAct's ability to synergistically combine reasoning and action, allowing it to iteratively refine its \u001b[0m\n",
       "\u001b[1;38;2;118;185;0munderstanding and actions based on external feedback.\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0mHere are some examples:\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0m**\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;38;2;118;185;0m.  Scientific Literature Retrieval and Reasoning:**  Integrating ReAct with APIs for scientific databases like \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mPubMed, Semantic Scholar, or arXiv could enable the model to answer complex scientific questions requiring \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mmulti-step reasoning across multiple papers.  This would allow for more accurate and nuanced answers than current \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mLLMs, which often hallucinate facts or misinterpret scientific findings.  The impact on reasoning would be a more \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mrobust and evidence-based approach, and the action capability would extend to retrieving and synthesizing \u001b[0m\n",
       "\u001b[1;38;2;118;185;0minformation from disparate sources.\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;38;2;118;185;0m.  Financial Market Analysis and Prediction:**  Connecting ReAct to financial data APIs \u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\u001b[1;38;2;118;185;0me.g., Alpha Vantage, \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mTiingo\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m would enable sophisticated financial analysis.  The model could reason through complex market trends, \u001b[0m\n",
       "\u001b[1;38;2;118;185;0manalyze company performance, and even formulate potential investment strategies by accessing and interpreting \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mreal-time market data. Reasoning would become more data-driven and precise, while actions would involve querying \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mAPIs for specific data points and formulating trades \u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\u001b[1;38;2;118;185;0min a simulated environment initially\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m.\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0m**\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;38;2;118;185;0m.  Legal Research and Argumentation:**  Integration with legal databases like Westlaw or LexisNexis would \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mrevolutionize legal research.  ReAct could analyze case law, statutes, and regulations to provide accurate and \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mcomprehensive legal opinions.  The reasoning capabilities would improve by utilizing precise legal language and \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mprecedents, while actions would include retrieving relevant legal documents and constructing logical legal \u001b[0m\n",
       "\u001b[1;38;2;118;185;0marguments.\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0m**\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;38;2;118;185;0m.  Medical Diagnosis and Treatment Planning \u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\u001b[1;38;2;118;185;0mSimulated Environment\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m:**  Within a simulated environment \u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\u001b[1;38;2;118;185;0mcrucial \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mfor safety\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m, ReAct could be integrated with medical knowledge bases and imaging APIs.  This could assist medical \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mprofessionals by analyzing patient data, suggesting potential diagnoses, and even outlining possible treatment \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mplans.  Reasoning would involve complex medical knowledge integration and risk assessment, while actions could \u001b[0m\n",
       "\u001b[1;38;2;118;185;0minvolve querying medical databases and creating treatment plans.  Ethical considerations and validation would be \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mparamount in any real-world application.\u001b[0m\n",
       "\n",
       "\n",
       "\u001b[1;38;2;118;185;0m**\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;38;2;118;185;0m.  Personalized Education and Tutoring:**  By connecting ReAct to educational APIs and databases, personalized \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mlearning experiences could be created.  The model could adapt its teaching style to individual student needs, \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mprovide targeted feedback, and generate custom learning materials.  Reasoning would involve understanding the \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mstudent's knowledge gaps and tailoring lessons accordingly, while actions would include selecting relevant learning\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mresources and providing personalized feedback.\u001b[0m\n",
       "\n",
       "\n",
       "\u001b[1;38;2;118;185;0mIn all these examples, the impact on ReAct's capabilities would be significant.  The iterative process of reasoning\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mand acting, guided by external information, would mitigate hallucination, improve accuracy, and produce more robust\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mand explainable outputs. The ability to handle complex, multi-step reasoning tasks across diverse domains would be \u001b[0m\n",
       "\u001b[1;38;2;118;185;0msignificantly enhanced.  However, careful consideration of ethical implications, bias in data sources, and the \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mpotential for misuse remains crucial for any real-world deployment.\u001b[0m\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rag_answers = []\n",
    "contexts = []\n",
    "for i, q in enumerate(synth_questions):\n",
    "    outp = rag_chain.invoke(q)\n",
    "    rag_answer = outp.get('output', '')\n",
    "    rag_answers += [rag_answer]\n",
    "    context = outp.get('context', '')\n",
    "    contexts += [context] \n",
    "    pprint2(f\"Q {i+1}\\n\", q, \"\", sep=\"\\n\")\n",
    "    pprint(f\"RAG Answer: \\n\\n{rag_answer}\", \"\", sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ho5cnN_Xt_yr",
   "metadata": {
    "id": "Ho5cnN_Xt_yr"
   },
   "source": [
    "### 5.5. Implementing Human Preference Metric\n",
    "\n",
    "Now we implement the fourth part of our evaluation routine:\n",
    "\n",
    "- Sample RAG agent document pool to find two document chunks.\n",
    "- Use those two document chunks to generate synthetic \"baseline\" question-answer pair.\n",
    "- Use RAG agent to generate its own answer.\n",
    "- **Use a judge LLM to compare the two responses while grounding the synthetic generation as \"ground-truth correct.\"**\n",
    "\n",
    "The chain should be a simple but powerful process that tests if the RAG chain outperforms a narrow chatbot with limited document access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "sf6f2oFLuPtu",
   "metadata": {
    "id": "sf6f2oFLuPtu",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Set </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "\n",
       "<span style=\"font-weight: bold\">Question: Question:  Considering the ReAct model's success in integrating reasoning and action, as exemplified by </span>\n",
       "<span style=\"font-weight: bold\">its ability to plan and execute actions like cleaning and placing a lettuce in the provided example, how might its </span>\n",
       "<span style=\"font-weight: bold\">interactive decision-making capabilities be further enhanced by incorporating more sophisticated environmental </span>\n",
       "<span style=\"font-weight: bold\">modeling and proactive planning beyond simple task completion?</span>\n",
       "\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mSet \u001b[0m\u001b[1;36m1\u001b[0m\n",
       "\n",
       "\u001b[1mQuestion: Question:  Considering the ReAct model's success in integrating reasoning and action, as exemplified by \u001b[0m\n",
       "\u001b[1mits ability to plan and execute actions like cleaning and placing a lettuce in the provided example, how might its \u001b[0m\n",
       "\u001b[1minteractive decision-making capabilities be further enhanced by incorporating more sophisticated environmental \u001b[0m\n",
       "\u001b[1mmodeling and proactive planning beyond simple task completion?\u001b[0m\n",
       "\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">RAG Answer: Answer: Enhancing ReAct's interactive decision-making capabilities beyond simple task completion </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">requires incorporating more sophisticated environmental modeling and proactive planning.  This could involve:</span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">. **Developing richer internal representations of the environment:**  Instead of relying on simple descriptions, </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">ReAct could benefit from integrating more detailed, structured environmental models. This might involve using </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">graph-based representations to capture object relationships, spatial layouts, and potential interactions.  This </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">would allow for more complex reasoning about the consequences of actions and more robust planning.</span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">. **Implementing proactive planning mechanisms:** Currently, ReAct's planning seems largely reactive.  More </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">sophisticated planning algorithms, such as Monte Carlo Tree Search (MCTS) or hierarchical planning, could be </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">incorporated to explore potential action sequences and evaluate their expected outcomes before execution.  This </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">proactive approach would enable anticipation of future needs and potential obstacles, leading to more efficient and</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">robust task completion.</span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">. **Integrating temporal reasoning:**  Adding temporal reasoning capabilities would allow ReAct to consider the </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">timing of actions and their dependencies. For instance, understanding that cleaning the lettuce must precede </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">placing it on the table is a simple example; more complex scenarios may require sophisticated scheduling and </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">resource management.</span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">. **Incorporating uncertainty and risk assessment:**  Real-world environments are inherently uncertain.  </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Augmenting ReAct with probabilistic models and risk assessment mechanisms would allow it to handle unexpected </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">events and make more robust decisions under uncertainty. For example, it could plan for alternative actions if a </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">required object is unavailable.</span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">. **Leveraging external knowledge bases:**  Integrating access to broader knowledge bases beyond simple APIs could</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">provide ReAct with more context and information for planning.  This could include knowledge about object </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">properties, typical action sequences, or potential hazards.</span>\n",
       "\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">By integrating these enhancements, ReAct could move beyond simple task completion towards more complex, adaptive, </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">and proactive interaction with the environment.  It would then be able to handle unforeseen circumstances, plan for</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">contingencies, and optimize its actions for efficiency and robustness.</span>\n",
       "\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mRAG Answer: Answer: Enhancing ReAct's interactive decision-making capabilities beyond simple task completion \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mrequires incorporating more sophisticated environmental modeling and proactive planning.  This could involve:\u001b[0m\n",
       "\n",
       "\u001b[1;36m1\u001b[0m\u001b[1;38;2;118;185;0m. **Developing richer internal representations of the environment:**  Instead of relying on simple descriptions, \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mReAct could benefit from integrating more detailed, structured environmental models. This might involve using \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mgraph-based representations to capture object relationships, spatial layouts, and potential interactions.  This \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mwould allow for more complex reasoning about the consequences of actions and more robust planning.\u001b[0m\n",
       "\n",
       "\u001b[1;36m2\u001b[0m\u001b[1;38;2;118;185;0m. **Implementing proactive planning mechanisms:** Currently, ReAct's planning seems largely reactive.  More \u001b[0m\n",
       "\u001b[1;38;2;118;185;0msophisticated planning algorithms, such as Monte Carlo Tree Search \u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\u001b[1;38;2;118;185;0mMCTS\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m or hierarchical planning, could be \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mincorporated to explore potential action sequences and evaluate their expected outcomes before execution.  This \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mproactive approach would enable anticipation of future needs and potential obstacles, leading to more efficient and\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mrobust task completion.\u001b[0m\n",
       "\n",
       "\u001b[1;36m3\u001b[0m\u001b[1;38;2;118;185;0m. **Integrating temporal reasoning:**  Adding temporal reasoning capabilities would allow ReAct to consider the \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mtiming of actions and their dependencies. For instance, understanding that cleaning the lettuce must precede \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mplacing it on the table is a simple example; more complex scenarios may require sophisticated scheduling and \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mresource management.\u001b[0m\n",
       "\n",
       "\u001b[1;36m4\u001b[0m\u001b[1;38;2;118;185;0m. **Incorporating uncertainty and risk assessment:**  Real-world environments are inherently uncertain.  \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mAugmenting ReAct with probabilistic models and risk assessment mechanisms would allow it to handle unexpected \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mevents and make more robust decisions under uncertainty. For example, it could plan for alternative actions if a \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mrequired object is unavailable.\u001b[0m\n",
       "\n",
       "\u001b[1;36m5\u001b[0m\u001b[1;38;2;118;185;0m. **Leveraging external knowledge bases:**  Integrating access to broader knowledge bases beyond simple APIs could\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mprovide ReAct with more context and information for planning.  This could include knowledge about object \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mproperties, typical action sequences, or potential hazards.\u001b[0m\n",
       "\n",
       "\n",
       "\u001b[1;38;2;118;185;0mBy integrating these enhancements, ReAct could move beyond simple task completion towards more complex, adaptive, \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mand proactive interaction with the environment.  It would then be able to handle unforeseen circumstances, plan for\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mcontingencies, and optimize its actions for efficiency and robustness.\u001b[0m\n",
       "\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Synth Answer: Answer: Enhancing ReAct's interactive decision-making capabilities beyond simple task completion </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">requires incorporating more sophisticated environmental modeling and proactive planning. This could involve:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">) </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">**Developing richer world models:**  Instead of relying on limited, immediate sensory input, integrating external </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">knowledge bases, maps, or object-relationship graphs would allow ReAct to reason about the environment more </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">comprehensively. This would enable proactive actions like anticipating obstacles before they are encountered (e.g.,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">planning a route around a cluttered area before starting to clean). </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">) **Hierarchical planning:**  Moving beyond </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">flat sequences of actions, hierarchical planning would allow ReAct to break down complex tasks into sub-tasks, </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">enabling more robust and flexible planning.  This would allow for contingency planning –  if an unexpected event </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">occurs (e.g., the lettuce is unexpectedly slippery), the system can adapt its plan without restarting. </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">) </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">**Predictive modeling:**  Incorporating predictive models of the environment and the effects of actions would allow</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">ReAct to simulate potential outcomes and choose actions that maximize the likelihood of success. For example, </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">predicting the trajectory of a moving object to avoid collisions while navigating. </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">) **Reinforcement learning with</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">long-term rewards:**  Training the model with rewards that incentivize efficient and proactive behavior, extending </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">beyond immediate task completion, would encourage the system to develop more sophisticated planning skills.  For </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">example, rewarding efficient route planning or minimizing energy consumption. </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">) **Uncertainty handling:**  </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Incorporating probabilistic reasoning and uncertainty quantification would make the system more robust to noisy or </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">incomplete information about the environment. This would allow ReAct to handle situations where perfect information</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">is unavailable and plan accordingly.  By incorporating these advancements, ReAct could evolve from a simple task </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">executor to a proactive and adaptable agent capable of complex, long-term planning and decision-making in dynamic </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">environments.</span>\n",
       "\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mSynth Answer: Answer: Enhancing ReAct's interactive decision-making capabilities beyond simple task completion \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mrequires incorporating more sophisticated environmental modeling and proactive planning. This could involve:  \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m \u001b[0m\n",
       "\u001b[1;38;2;118;185;0m**Developing richer world models:**  Instead of relying on limited, immediate sensory input, integrating external \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mknowledge bases, maps, or object-relationship graphs would allow ReAct to reason about the environment more \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mcomprehensively. This would enable proactive actions like anticipating obstacles before they are encountered \u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\u001b[1;38;2;118;185;0me.g.,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mplanning a route around a cluttered area before starting to clean\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m. \u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m **Hierarchical planning:**  Moving beyond \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mflat sequences of actions, hierarchical planning would allow ReAct to break down complex tasks into sub-tasks, \u001b[0m\n",
       "\u001b[1;38;2;118;185;0menabling more robust and flexible planning.  This would allow for contingency planning –  if an unexpected event \u001b[0m\n",
       "\u001b[1;38;2;118;185;0moccurs \u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\u001b[1;38;2;118;185;0me.g., the lettuce is unexpectedly slippery\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m, the system can adapt its plan without restarting. \u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m \u001b[0m\n",
       "\u001b[1;38;2;118;185;0m**Predictive modeling:**  Incorporating predictive models of the environment and the effects of actions would allow\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mReAct to simulate potential outcomes and choose actions that maximize the likelihood of success. For example, \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mpredicting the trajectory of a moving object to avoid collisions while navigating. \u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m **Reinforcement learning with\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mlong-term rewards:**  Training the model with rewards that incentivize efficient and proactive behavior, extending \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mbeyond immediate task completion, would encourage the system to develop more sophisticated planning skills.  For \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mexample, rewarding efficient route planning or minimizing energy consumption. \u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m **Uncertainty handling:**  \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mIncorporating probabilistic reasoning and uncertainty quantification would make the system more robust to noisy or \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mincomplete information about the environment. This would allow ReAct to handle situations where perfect information\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mis unavailable and plan accordingly.  By incorporating these advancements, ReAct could evolve from a simple task \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mexecutor to a proactive and adaptable agent capable of complex, long-term planning and decision-making in dynamic \u001b[0m\n",
       "\u001b[1;38;2;118;185;0menvironments.\u001b[0m\n",
       "\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Synth Evaluation: [</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">] Justification:</span>\n",
       "\n",
       "<span style=\"font-weight: bold\">Answer </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\"> provides a more precise and detailed breakdown of how to enhance ReAct's capabilities.  While Answer </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\"> </span>\n",
       "<span style=\"font-weight: bold\">touches upon similar concepts, Answer </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\"> offers more specific examples and suggestions. For instance, Answer </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\"> </span>\n",
       "<span style=\"font-weight: bold\">explicitly mentions Monte Carlo Tree Search (MCTS) and hierarchical planning as specific algorithmic solutions, </span>\n",
       "<span style=\"font-weight: bold\">offering a greater level of technical depth.  The inclusion of temporal reasoning and the explicit mention of </span>\n",
       "<span style=\"font-weight: bold\">handling uncertainty with probabilistic models adds further precision to Answer </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">'s recommendations. Answer </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">'s </span>\n",
       "<span style=\"font-weight: bold\">points are more broadly stated, lacking the same level of specific detail in its suggestions for improvement.  </span>\n",
       "<span style=\"font-weight: bold\">Therefore, Answer </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\"> is superior in terms of accuracy and precision.</span>\n",
       "\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mSynth Evaluation: \u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\u001b[1m Justification:\u001b[0m\n",
       "\n",
       "\u001b[1mAnswer \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m provides a more precise and detailed breakdown of how to enhance ReAct's capabilities.  While Answer \u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m \u001b[0m\n",
       "\u001b[1mtouches upon similar concepts, Answer \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m offers more specific examples and suggestions. For instance, Answer \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m \u001b[0m\n",
       "\u001b[1mexplicitly mentions Monte Carlo Tree Search \u001b[0m\u001b[1m(\u001b[0m\u001b[1mMCTS\u001b[0m\u001b[1m)\u001b[0m\u001b[1m and hierarchical planning as specific algorithmic solutions, \u001b[0m\n",
       "\u001b[1moffering a greater level of technical depth.  The inclusion of temporal reasoning and the explicit mention of \u001b[0m\n",
       "\u001b[1mhandling uncertainty with probabilistic models adds further precision to Answer \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m's recommendations. Answer \u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m's \u001b[0m\n",
       "\u001b[1mpoints are more broadly stated, lacking the same level of specific detail in its suggestions for improvement.  \u001b[0m\n",
       "\u001b[1mTherefore, Answer \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m is superior in terms of accuracy and precision.\u001b[0m\n",
       "\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Set </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "\n",
       "<span style=\"font-weight: bold\">Question: Question: Given the limitations of Large Language Models highlighted in the provided text, and the </span>\n",
       "<span style=\"font-weight: bold\">presented data on the performance of different mathematical formula structures within the MRKL system, how might </span>\n",
       "<span style=\"font-weight: bold\">the specific strengths and weaknesses of neuro-symbolic architectures like MRKL be leveraged to improve the </span>\n",
       "<span style=\"font-weight: bold\">accuracy and reliability of complex mathematical reasoning tasks in AI systems?</span>\n",
       "\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mSet \u001b[0m\u001b[1;36m2\u001b[0m\n",
       "\n",
       "\u001b[1mQuestion: Question: Given the limitations of Large Language Models highlighted in the provided text, and the \u001b[0m\n",
       "\u001b[1mpresented data on the performance of different mathematical formula structures within the MRKL system, how might \u001b[0m\n",
       "\u001b[1mthe specific strengths and weaknesses of neuro-symbolic architectures like MRKL be leveraged to improve the \u001b[0m\n",
       "\u001b[1maccuracy and reliability of complex mathematical reasoning tasks in AI systems?\u001b[0m\n",
       "\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">RAG Answer: Answer: The provided text highlights limitations of Large Language Models (LLMs), such as a lack of </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">access to current/proprietary information and an inability to reason symbolically.  MRKL, a neuro-symbolic </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">architecture, addresses these weaknesses by combining LLMs with external knowledge sources and discrete reasoning </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">modules.  To improve accuracy and reliability in complex mathematical reasoning, MRKL's strengths can be leveraged </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">as follows:</span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">. **Symbolic Reasoning for Precise Calculations:**  LLMs excel at natural language processing but struggle with </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">precise, symbolic manipulation needed for complex mathematics.  MRKL's discrete reasoning modules can handle this, </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">ensuring accurate execution of mathematical formulas and algorithms regardless of their complexity or the need for </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">specialized knowledge.  The system can translate natural language problem statements into symbolic representations,</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">allowing the reasoning module to perform calculations, and then translate the result back into natural language.</span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">. **Knowledge Integration for Contextual Understanding:**  LLMs may lack access to specific data or formulas </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">necessary for advanced mathematical tasks.  MRKL's integration of external knowledge sources (databases, </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">specialized libraries, etc.) provides access to this information, enabling the system to correctly interpret the </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">context of a problem and select the appropriate formulas and data.</span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">. **Modular Design for Flexibility and Scalability:** The modular design of MRKL allows for the addition of new </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">knowledge modules and reasoning capabilities as needed. This flexibility makes it adaptable to various mathematical</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">domains and facilitates easier expansion for tackling more intricate problems.</span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">. **Hybrid Approach for Enhanced Performance:**  MRKL's combination of LLMs and symbolic reasoning creates a </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">synergistic effect. LLMs can be used for initial problem understanding, formula extraction from textual </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">descriptions, and final result interpretation, while the symbolic modules handle the computationally intensive </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">parts.</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">However, challenges remain. The text mentions difficulties in intelligently routing inputs between modules and </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">avoiding model explosion.  Future development of MRKL should focus on optimizing these aspects to improve </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">efficiency and scalability for even more complex mathematical problems.  Furthermore, careful consideration needs </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">to be given to the selection and integration of external knowledge sources to ensure accuracy and reliability of </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">the information used.</span>\n",
       "\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mRAG Answer: Answer: The provided text highlights limitations of Large Language Models \u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\u001b[1;38;2;118;185;0mLLMs\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m, such as a lack of \u001b[0m\n",
       "\u001b[1;38;2;118;185;0maccess to current/proprietary information and an inability to reason symbolically.  MRKL, a neuro-symbolic \u001b[0m\n",
       "\u001b[1;38;2;118;185;0marchitecture, addresses these weaknesses by combining LLMs with external knowledge sources and discrete reasoning \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mmodules.  To improve accuracy and reliability in complex mathematical reasoning, MRKL's strengths can be leveraged \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mas follows:\u001b[0m\n",
       "\n",
       "\u001b[1;36m1\u001b[0m\u001b[1;38;2;118;185;0m. **Symbolic Reasoning for Precise Calculations:**  LLMs excel at natural language processing but struggle with \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mprecise, symbolic manipulation needed for complex mathematics.  MRKL's discrete reasoning modules can handle this, \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mensuring accurate execution of mathematical formulas and algorithms regardless of their complexity or the need for \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mspecialized knowledge.  The system can translate natural language problem statements into symbolic representations,\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mallowing the reasoning module to perform calculations, and then translate the result back into natural language.\u001b[0m\n",
       "\n",
       "\u001b[1;36m2\u001b[0m\u001b[1;38;2;118;185;0m. **Knowledge Integration for Contextual Understanding:**  LLMs may lack access to specific data or formulas \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mnecessary for advanced mathematical tasks.  MRKL's integration of external knowledge sources \u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\u001b[1;38;2;118;185;0mdatabases, \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mspecialized libraries, etc.\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m provides access to this information, enabling the system to correctly interpret the \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mcontext of a problem and select the appropriate formulas and data.\u001b[0m\n",
       "\n",
       "\u001b[1;36m3\u001b[0m\u001b[1;38;2;118;185;0m. **Modular Design for Flexibility and Scalability:** The modular design of MRKL allows for the addition of new \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mknowledge modules and reasoning capabilities as needed. This flexibility makes it adaptable to various mathematical\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mdomains and facilitates easier expansion for tackling more intricate problems.\u001b[0m\n",
       "\n",
       "\u001b[1;36m4\u001b[0m\u001b[1;38;2;118;185;0m. **Hybrid Approach for Enhanced Performance:**  MRKL's combination of LLMs and symbolic reasoning creates a \u001b[0m\n",
       "\u001b[1;38;2;118;185;0msynergistic effect. LLMs can be used for initial problem understanding, formula extraction from textual \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mdescriptions, and final result interpretation, while the symbolic modules handle the computationally intensive \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mparts.\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0mHowever, challenges remain. The text mentions difficulties in intelligently routing inputs between modules and \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mavoiding model explosion.  Future development of MRKL should focus on optimizing these aspects to improve \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mefficiency and scalability for even more complex mathematical problems.  Furthermore, careful consideration needs \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mto be given to the selection and integration of external knowledge sources to ensure accuracy and reliability of \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mthe information used.\u001b[0m\n",
       "\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Synth Answer: Answer:  Neuro-symbolic architectures like MRKL, by combining the strengths of neural networks </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(pattern recognition, generalization) and symbolic AI (explicit knowledge representation, logical reasoning), can </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">mitigate the limitations of LLMs in complex mathematical reasoning.  The data on MRKL's performance with different </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">formula structures highlights the importance of carefully designing the symbolic component to represent </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">mathematical knowledge effectively.  To improve accuracy and reliability, we can leverage MRKL's strengths as </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">follows:</span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">. **Improved Knowledge Representation:**  Use MRKL's symbolic reasoning capabilities to explicitly encode </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">mathematical axioms, theorems, and rules of inference.  This addresses LLMs' weakness in lacking explicit </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">understanding of mathematical concepts and relying on statistical correlations.  Analyzing the MRKL data to </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">identify optimal formula structures for encoding different mathematical domains would be crucial.</span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">. **Hybrid Approach:**  Combine the neural network's capacity for learning complex patterns with the symbolic </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">system's ability to perform deductive reasoning. The neural network can be trained on large datasets to learn </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">approximations and heuristic strategies, while the symbolic component ensures correctness and consistency. This </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">allows leveraging the strengths of both while minimizing their individual weaknesses.</span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">. **Explainability and Interpretability:**  The symbolic representation in MRKL allows for tracing the reasoning </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">steps, providing explainability absent in purely neural network approaches.  This interpretability is crucial for </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">debugging errors and building trust in the AI's mathematical conclusions.  Analyzing where MRKL falters (as </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">revealed by the performance data) can guide the improvement of both symbolic representations and the integration </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">with the neural component.</span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">. **Targeted Training:** Instead of relying on large-scale general training, focus on targeted training of the </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">neural components of MRKL on specific sub-problems or mathematical domains, informed by the performance data on </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">formula structures. This refined training can improve accuracy and address the limitations identified in the </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">specific mathematical formula types.</span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">. **Iterative Refinement:** Use the performance data on MRKL as feedback to iteratively refine both the symbolic </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">knowledge base and the neural network's architecture and training methodology. This continuous improvement cycle is</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">key to addressing the limitations of both approaches and maximizing the combined strengths.</span>\n",
       "\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">In essence, a well-designed neuro-symbolic system like MRKL can create a robust and reliable AI system for complex </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">mathematical reasoning by leveraging its capacity for both learning and logical deduction, provided that the </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">symbolic component is carefully designed and the interaction between symbolic and neural components is optimized, </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">informed by data-driven insights.</span>\n",
       "\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mSynth Answer: Answer:  Neuro-symbolic architectures like MRKL, by combining the strengths of neural networks \u001b[0m\n",
       "\u001b[1;38;2;118;185;0m(\u001b[0m\u001b[1;38;2;118;185;0mpattern recognition, generalization\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m and symbolic AI \u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\u001b[1;38;2;118;185;0mexplicit knowledge representation, logical reasoning\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m, can \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mmitigate the limitations of LLMs in complex mathematical reasoning.  The data on MRKL's performance with different \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mformula structures highlights the importance of carefully designing the symbolic component to represent \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mmathematical knowledge effectively.  To improve accuracy and reliability, we can leverage MRKL's strengths as \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mfollows:\u001b[0m\n",
       "\n",
       "\u001b[1;36m1\u001b[0m\u001b[1;38;2;118;185;0m. **Improved Knowledge Representation:**  Use MRKL's symbolic reasoning capabilities to explicitly encode \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mmathematical axioms, theorems, and rules of inference.  This addresses LLMs' weakness in lacking explicit \u001b[0m\n",
       "\u001b[1;38;2;118;185;0munderstanding of mathematical concepts and relying on statistical correlations.  Analyzing the MRKL data to \u001b[0m\n",
       "\u001b[1;38;2;118;185;0midentify optimal formula structures for encoding different mathematical domains would be crucial.\u001b[0m\n",
       "\n",
       "\u001b[1;36m2\u001b[0m\u001b[1;38;2;118;185;0m. **Hybrid Approach:**  Combine the neural network's capacity for learning complex patterns with the symbolic \u001b[0m\n",
       "\u001b[1;38;2;118;185;0msystem's ability to perform deductive reasoning. The neural network can be trained on large datasets to learn \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mapproximations and heuristic strategies, while the symbolic component ensures correctness and consistency. This \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mallows leveraging the strengths of both while minimizing their individual weaknesses.\u001b[0m\n",
       "\n",
       "\u001b[1;36m3\u001b[0m\u001b[1;38;2;118;185;0m. **Explainability and Interpretability:**  The symbolic representation in MRKL allows for tracing the reasoning \u001b[0m\n",
       "\u001b[1;38;2;118;185;0msteps, providing explainability absent in purely neural network approaches.  This interpretability is crucial for \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mdebugging errors and building trust in the AI's mathematical conclusions.  Analyzing where MRKL falters \u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\u001b[1;38;2;118;185;0mas \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mrevealed by the performance data\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m can guide the improvement of both symbolic representations and the integration \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mwith the neural component.\u001b[0m\n",
       "\n",
       "\u001b[1;36m4\u001b[0m\u001b[1;38;2;118;185;0m. **Targeted Training:** Instead of relying on large-scale general training, focus on targeted training of the \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mneural components of MRKL on specific sub-problems or mathematical domains, informed by the performance data on \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mformula structures. This refined training can improve accuracy and address the limitations identified in the \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mspecific mathematical formula types.\u001b[0m\n",
       "\n",
       "\u001b[1;36m5\u001b[0m\u001b[1;38;2;118;185;0m. **Iterative Refinement:** Use the performance data on MRKL as feedback to iteratively refine both the symbolic \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mknowledge base and the neural network's architecture and training methodology. This continuous improvement cycle is\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mkey to addressing the limitations of both approaches and maximizing the combined strengths.\u001b[0m\n",
       "\n",
       "\n",
       "\u001b[1;38;2;118;185;0mIn essence, a well-designed neuro-symbolic system like MRKL can create a robust and reliable AI system for complex \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mmathematical reasoning by leveraging its capacity for both learning and logical deduction, provided that the \u001b[0m\n",
       "\u001b[1;38;2;118;185;0msymbolic component is carefully designed and the interaction between symbolic and neural components is optimized, \u001b[0m\n",
       "\u001b[1;38;2;118;185;0minformed by data-driven insights.\u001b[0m\n",
       "\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Synth Evaluation: [</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">] Justification: Answer </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\"> provides a more precise and detailed explanation of how MRKL's </span>\n",
       "<span style=\"font-weight: bold\">specific features address the limitations of LLMs in mathematical reasoning.  It offers concrete examples (e.g., </span>\n",
       "<span style=\"font-weight: bold\">translation between natural language and symbolic representations) and directly connects the MRKL system's </span>\n",
       "<span style=\"font-weight: bold\">components (LLMs, external knowledge sources, reasoning modules) to the solution of improving accuracy and </span>\n",
       "<span style=\"font-weight: bold\">reliability.  Answer </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">, while offering valid points, remains more general and less specific in its connection to </span>\n",
       "<span style=\"font-weight: bold\">MRKL's architecture and functionality.  For example, it mentions </span><span style=\"color: #008000; text-decoration-color: #008000\">\"improved knowledge representation\"</span><span style=\"font-weight: bold\"> without </span>\n",
       "<span style=\"font-weight: bold\">explicitly detailing how MRKL's structure facilitates this, unlike Answer </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">'s explicit discussion of symbolic </span>\n",
       "<span style=\"font-weight: bold\">reasoning modules and knowledge integration.  Answer </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\"> also more thoroughly addresses potential challenges and </span>\n",
       "<span style=\"font-weight: bold\">future development directions, thus showing a more complete understanding of the subject matter.</span>\n",
       "\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mSynth Evaluation: \u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\u001b[1m Justification: Answer \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m provides a more precise and detailed explanation of how MRKL's \u001b[0m\n",
       "\u001b[1mspecific features address the limitations of LLMs in mathematical reasoning.  It offers concrete examples \u001b[0m\u001b[1m(\u001b[0m\u001b[1me.g., \u001b[0m\n",
       "\u001b[1mtranslation between natural language and symbolic representations\u001b[0m\u001b[1m)\u001b[0m\u001b[1m and directly connects the MRKL system's \u001b[0m\n",
       "\u001b[1mcomponents \u001b[0m\u001b[1m(\u001b[0m\u001b[1mLLMs, external knowledge sources, reasoning modules\u001b[0m\u001b[1m)\u001b[0m\u001b[1m to the solution of improving accuracy and \u001b[0m\n",
       "\u001b[1mreliability.  Answer \u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m, while offering valid points, remains more general and less specific in its connection to \u001b[0m\n",
       "\u001b[1mMRKL's architecture and functionality.  For example, it mentions \u001b[0m\u001b[32m\"improved knowledge representation\"\u001b[0m\u001b[1m without \u001b[0m\n",
       "\u001b[1mexplicitly detailing how MRKL's structure facilitates this, unlike Answer \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m's explicit discussion of symbolic \u001b[0m\n",
       "\u001b[1mreasoning modules and knowledge integration.  Answer \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m also more thoroughly addresses potential challenges and \u001b[0m\n",
       "\u001b[1mfuture development directions, thus showing a more complete understanding of the subject matter.\u001b[0m\n",
       "\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Set </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>\n",
       "\n",
       "<span style=\"font-weight: bold\">Question: Question:  Given the ReAct model's demonstrated success in mitigating hallucination and error propagation</span>\n",
       "<span style=\"font-weight: bold\">in question answering and fact verification by interacting with a Wikipedia API, what novel applications could be </span>\n",
       "<span style=\"font-weight: bold\">explored by integrating ReAct with other external knowledge bases or APIs, and how might this impact the model's </span>\n",
       "<span style=\"font-weight: bold\">reasoning and action capabilities across diverse tasks?</span>\n",
       "\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mSet \u001b[0m\u001b[1;36m3\u001b[0m\n",
       "\n",
       "\u001b[1mQuestion: Question:  Given the ReAct model's demonstrated success in mitigating hallucination and error propagation\u001b[0m\n",
       "\u001b[1min question answering and fact verification by interacting with a Wikipedia API, what novel applications could be \u001b[0m\n",
       "\u001b[1mexplored by integrating ReAct with other external knowledge bases or APIs, and how might this impact the model's \u001b[0m\n",
       "\u001b[1mreasoning and action capabilities across diverse tasks?\u001b[0m\n",
       "\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">RAG Answer: Answer: Integrating ReAct with various external knowledge bases and APIs beyond Wikipedia could unlock </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">numerous novel applications and significantly enhance its reasoning and action capabilities across diverse tasks.  </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">The key is ReAct's ability to synergistically combine reasoning and action, allowing it to iteratively refine its </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">understanding and actions based on external feedback.</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Here are some examples:</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">**</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">.  Scientific Literature Retrieval and Reasoning:**  Integrating ReAct with APIs for scientific databases like </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">PubMed, Semantic Scholar, or arXiv could enable the model to answer complex scientific questions requiring </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">multi-step reasoning across multiple papers.  This would allow for more accurate and nuanced answers than current </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">LLMs, which often hallucinate facts or misinterpret scientific findings.  The impact on reasoning would be a more </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">robust and evidence-based approach, and the action capability would extend to retrieving and synthesizing </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">information from disparate sources.</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">**</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">.  Financial Market Analysis and Prediction:**  Connecting ReAct to financial data APIs (e.g., Alpha Vantage, </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Tiingo) would enable sophisticated financial analysis.  The model could reason through complex market trends, </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">analyze company performance, and even formulate potential investment strategies by accessing and interpreting </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">real-time market data. Reasoning would become more data-driven and precise, while actions would involve querying </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">APIs for specific data points and formulating trades (in a simulated environment initially).</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">**</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">.  Legal Research and Argumentation:**  Integration with legal databases like Westlaw or LexisNexis would </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">revolutionize legal research.  ReAct could analyze case law, statutes, and regulations to provide accurate and </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">comprehensive legal opinions.  The reasoning capabilities would improve by utilizing precise legal language and </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">precedents, while actions would include retrieving relevant legal documents and constructing logical legal </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">arguments.</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">**</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">.  Medical Diagnosis and Treatment Planning (Simulated Environment):**  Within a simulated environment (crucial </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">for safety), ReAct could be integrated with medical knowledge bases and imaging APIs.  This could assist medical </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">professionals by analyzing patient data, suggesting potential diagnoses, and even outlining possible treatment </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">plans.  Reasoning would involve complex medical knowledge integration and risk assessment, while actions could </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">involve querying medical databases and creating treatment plans.  Ethical considerations and validation would be </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">paramount in any real-world application.</span>\n",
       "\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">**</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">.  Personalized Education and Tutoring:**  By connecting ReAct to educational APIs and databases, personalized </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">learning experiences could be created.  The model could adapt its teaching style to individual student needs, </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">provide targeted feedback, and generate custom learning materials.  Reasoning would involve understanding the </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">student's knowledge gaps and tailoring lessons accordingly, while actions would include selecting relevant learning</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">resources and providing personalized feedback.</span>\n",
       "\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">In all these examples, the impact on ReAct's capabilities would be significant.  The iterative process of reasoning</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">and acting, guided by external information, would mitigate hallucination, improve accuracy, and produce more robust</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">and explainable outputs. The ability to handle complex, multi-step reasoning tasks across diverse domains would be </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">significantly enhanced.  However, careful consideration of ethical implications, bias in data sources, and the </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">potential for misuse remains crucial for any real-world deployment.</span>\n",
       "\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mRAG Answer: Answer: Integrating ReAct with various external knowledge bases and APIs beyond Wikipedia could unlock \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mnumerous novel applications and significantly enhance its reasoning and action capabilities across diverse tasks.  \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mThe key is ReAct's ability to synergistically combine reasoning and action, allowing it to iteratively refine its \u001b[0m\n",
       "\u001b[1;38;2;118;185;0munderstanding and actions based on external feedback.\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0mHere are some examples:\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0m**\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;38;2;118;185;0m.  Scientific Literature Retrieval and Reasoning:**  Integrating ReAct with APIs for scientific databases like \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mPubMed, Semantic Scholar, or arXiv could enable the model to answer complex scientific questions requiring \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mmulti-step reasoning across multiple papers.  This would allow for more accurate and nuanced answers than current \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mLLMs, which often hallucinate facts or misinterpret scientific findings.  The impact on reasoning would be a more \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mrobust and evidence-based approach, and the action capability would extend to retrieving and synthesizing \u001b[0m\n",
       "\u001b[1;38;2;118;185;0minformation from disparate sources.\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;38;2;118;185;0m.  Financial Market Analysis and Prediction:**  Connecting ReAct to financial data APIs \u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\u001b[1;38;2;118;185;0me.g., Alpha Vantage, \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mTiingo\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m would enable sophisticated financial analysis.  The model could reason through complex market trends, \u001b[0m\n",
       "\u001b[1;38;2;118;185;0manalyze company performance, and even formulate potential investment strategies by accessing and interpreting \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mreal-time market data. Reasoning would become more data-driven and precise, while actions would involve querying \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mAPIs for specific data points and formulating trades \u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\u001b[1;38;2;118;185;0min a simulated environment initially\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m.\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0m**\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;38;2;118;185;0m.  Legal Research and Argumentation:**  Integration with legal databases like Westlaw or LexisNexis would \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mrevolutionize legal research.  ReAct could analyze case law, statutes, and regulations to provide accurate and \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mcomprehensive legal opinions.  The reasoning capabilities would improve by utilizing precise legal language and \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mprecedents, while actions would include retrieving relevant legal documents and constructing logical legal \u001b[0m\n",
       "\u001b[1;38;2;118;185;0marguments.\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0m**\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;38;2;118;185;0m.  Medical Diagnosis and Treatment Planning \u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\u001b[1;38;2;118;185;0mSimulated Environment\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m:**  Within a simulated environment \u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\u001b[1;38;2;118;185;0mcrucial \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mfor safety\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m, ReAct could be integrated with medical knowledge bases and imaging APIs.  This could assist medical \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mprofessionals by analyzing patient data, suggesting potential diagnoses, and even outlining possible treatment \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mplans.  Reasoning would involve complex medical knowledge integration and risk assessment, while actions could \u001b[0m\n",
       "\u001b[1;38;2;118;185;0minvolve querying medical databases and creating treatment plans.  Ethical considerations and validation would be \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mparamount in any real-world application.\u001b[0m\n",
       "\n",
       "\n",
       "\u001b[1;38;2;118;185;0m**\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;38;2;118;185;0m.  Personalized Education and Tutoring:**  By connecting ReAct to educational APIs and databases, personalized \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mlearning experiences could be created.  The model could adapt its teaching style to individual student needs, \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mprovide targeted feedback, and generate custom learning materials.  Reasoning would involve understanding the \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mstudent's knowledge gaps and tailoring lessons accordingly, while actions would include selecting relevant learning\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mresources and providing personalized feedback.\u001b[0m\n",
       "\n",
       "\n",
       "\u001b[1;38;2;118;185;0mIn all these examples, the impact on ReAct's capabilities would be significant.  The iterative process of reasoning\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mand acting, guided by external information, would mitigate hallucination, improve accuracy, and produce more robust\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mand explainable outputs. The ability to handle complex, multi-step reasoning tasks across diverse domains would be \u001b[0m\n",
       "\u001b[1;38;2;118;185;0msignificantly enhanced.  However, careful consideration of ethical implications, bias in data sources, and the \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mpotential for misuse remains crucial for any real-world deployment.\u001b[0m\n",
       "\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Synth Answer: Answer: Integrating ReAct with other external knowledge bases and APIs beyond Wikipedia could unlock </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">numerous novel applications and significantly enhance its reasoning and action capabilities.  Here are some </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">examples:</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">**Novel Applications:**</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">* **Scientific Discovery and Hypothesis Generation:**  ReAct could be integrated with scientific databases like </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">PubMed, Reaxys, or arXiv.  This would allow it to formulate hypotheses, design experiments, and interpret results </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">by referencing relevant literature and data, potentially accelerating scientific breakthroughs.  The model could </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">reason about complex biological pathways, chemical reactions, or astronomical phenomena by accessing and processing</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">information from these specialized sources.</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">* **Financial Modeling and Risk Assessment:** Combining ReAct with financial APIs (e.g., accessing real-time market</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">data, company financials, economic indicators) could enable sophisticated financial modeling, risk assessment, and </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">investment strategy generation. The model could analyze market trends, predict future performance, and make </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">informed investment decisions based on the data it retrieves and processes.</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">* **Personalized Healthcare and Medical Diagnosis Support:**  Integrating ReAct with Electronic Health Records </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(EHR) systems and medical knowledge bases could assist doctors in diagnosis and treatment planning.  The model </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">could analyze patient data, identify potential diagnoses, suggest relevant treatments, and even anticipate </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">potential complications based on its access to medical literature and patient histories. However, ethical </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">considerations regarding patient privacy and data security would need careful attention.</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">* **Legal Research and Due Diligence:**  Access to legal databases (e.g., Westlaw, LexisNexis) would allow ReAct to</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">perform legal research, identify relevant case law, and assist in due diligence processes. This could significantly</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">streamline legal workflows and improve the accuracy of legal advice.</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">* **Supply Chain Optimization and Logistics:**  Integration with real-time logistics and supply chain data APIs </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">could allow ReAct to optimize inventory management, predict disruptions, and suggest efficient routing strategies. </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">This could lead to cost savings and increased efficiency in supply chains.</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">**Impact on Reasoning and Action Capabilities:**</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">Integrating ReAct with diverse external knowledge bases would:</span>\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">* **Expand its knowledge domain:**  ReAct's capabilities would no longer be limited to the information available </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">within Wikipedia.  It could access and process information from specialized domains, significantly broadening its </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">scope.</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">* **Improve reasoning accuracy:**  Access to more comprehensive and up-to-date information would reduce </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">hallucination and improve the accuracy of its reasoning and conclusions.</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">* **Enable more complex reasoning tasks:**  The ability to interact with multiple data sources would allow ReAct to</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">perform more complex reasoning tasks that require synthesizing information from diverse sources.</span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">* **Enhance action capabilities:** The model's ability to directly interact with and manipulate external systems </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">(e.g., making API calls to update databases, trigger actions in a robotic system) would enable more sophisticated </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">actions.</span>\n",
       "\n",
       "\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">However, challenges remain: ensuring data quality, managing API rate limits, dealing with conflicting information </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">from different sources, and addressing potential biases in the data accessed are crucial considerations for </span>\n",
       "<span style=\"color: #76b900; text-decoration-color: #76b900; font-weight: bold\">successful integration.</span>\n",
       "\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;118;185;0mSynth Answer: Answer: Integrating ReAct with other external knowledge bases and APIs beyond Wikipedia could unlock \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mnumerous novel applications and significantly enhance its reasoning and action capabilities.  Here are some \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mexamples:\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0m**Novel Applications:**\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0m* **Scientific Discovery and Hypothesis Generation:**  ReAct could be integrated with scientific databases like \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mPubMed, Reaxys, or arXiv.  This would allow it to formulate hypotheses, design experiments, and interpret results \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mby referencing relevant literature and data, potentially accelerating scientific breakthroughs.  The model could \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mreason about complex biological pathways, chemical reactions, or astronomical phenomena by accessing and processing\u001b[0m\n",
       "\u001b[1;38;2;118;185;0minformation from these specialized sources.\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0m* **Financial Modeling and Risk Assessment:** Combining ReAct with financial APIs \u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\u001b[1;38;2;118;185;0me.g., accessing real-time market\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mdata, company financials, economic indicators\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m could enable sophisticated financial modeling, risk assessment, and \u001b[0m\n",
       "\u001b[1;38;2;118;185;0minvestment strategy generation. The model could analyze market trends, predict future performance, and make \u001b[0m\n",
       "\u001b[1;38;2;118;185;0minformed investment decisions based on the data it retrieves and processes.\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0m* **Personalized Healthcare and Medical Diagnosis Support:**  Integrating ReAct with Electronic Health Records \u001b[0m\n",
       "\u001b[1;38;2;118;185;0m(\u001b[0m\u001b[1;38;2;118;185;0mEHR\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m systems and medical knowledge bases could assist doctors in diagnosis and treatment planning.  The model \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mcould analyze patient data, identify potential diagnoses, suggest relevant treatments, and even anticipate \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mpotential complications based on its access to medical literature and patient histories. However, ethical \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mconsiderations regarding patient privacy and data security would need careful attention.\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0m* **Legal Research and Due Diligence:**  Access to legal databases \u001b[0m\u001b[1;38;2;118;185;0m(\u001b[0m\u001b[1;38;2;118;185;0me.g., Westlaw, LexisNexis\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m would allow ReAct to\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mperform legal research, identify relevant case law, and assist in due diligence processes. This could significantly\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mstreamline legal workflows and improve the accuracy of legal advice.\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0m* **Supply Chain Optimization and Logistics:**  Integration with real-time logistics and supply chain data APIs \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mcould allow ReAct to optimize inventory management, predict disruptions, and suggest efficient routing strategies. \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mThis could lead to cost savings and increased efficiency in supply chains.\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0m**Impact on Reasoning and Action Capabilities:**\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0mIntegrating ReAct with diverse external knowledge bases would:\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;118;185;0m* **Expand its knowledge domain:**  ReAct's capabilities would no longer be limited to the information available \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mwithin Wikipedia.  It could access and process information from specialized domains, significantly broadening its \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mscope.\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m* **Improve reasoning accuracy:**  Access to more comprehensive and up-to-date information would reduce \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mhallucination and improve the accuracy of its reasoning and conclusions.\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m* **Enable more complex reasoning tasks:**  The ability to interact with multiple data sources would allow ReAct to\u001b[0m\n",
       "\u001b[1;38;2;118;185;0mperform more complex reasoning tasks that require synthesizing information from diverse sources.\u001b[0m\n",
       "\u001b[1;38;2;118;185;0m* **Enhance action capabilities:** The model's ability to directly interact with and manipulate external systems \u001b[0m\n",
       "\u001b[1;38;2;118;185;0m(\u001b[0m\u001b[1;38;2;118;185;0me.g., making API calls to update databases, trigger actions in a robotic system\u001b[0m\u001b[1;38;2;118;185;0m)\u001b[0m\u001b[1;38;2;118;185;0m would enable more sophisticated \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mactions.\u001b[0m\n",
       "\n",
       "\n",
       "\u001b[1;38;2;118;185;0mHowever, challenges remain: ensuring data quality, managing API rate limits, dealing with conflicting information \u001b[0m\n",
       "\u001b[1;38;2;118;185;0mfrom different sources, and addressing potential biases in the data accessed are crucial considerations for \u001b[0m\n",
       "\u001b[1;38;2;118;185;0msuccessful integration.\u001b[0m\n",
       "\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Synth Evaluation: [</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">] Justification: Answer </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\"> provides more specific and detailed examples of novel applications of</span>\n",
       "<span style=\"font-weight: bold\">ReAct integrated with various APIs.  Each example (scientific literature, finance, legal research, simulated </span>\n",
       "<span style=\"font-weight: bold\">medical diagnosis, personalized education) is clearly explained, including how the integration would impact both </span>\n",
       "<span style=\"font-weight: bold\">the reasoning and action capabilities of the model.  Answer </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\"> offers good examples as well, but they are less </span>\n",
       "<span style=\"font-weight: bold\">detailed in explaining the impact on reasoning and action.  For example, </span><span style=\"color: #008000; text-decoration-color: #008000\">\"Scientific Discovery and Hypothesis </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Generation\"</span><span style=\"font-weight: bold\"> is mentioned but lacks the granular explanation provided by Answer </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">'s </span><span style=\"color: #008000; text-decoration-color: #008000\">\"Scientific Literature Retrieval</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and Reasoning.\"</span><span style=\"font-weight: bold\">  Answer </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">'s inclusion of ethical considerations in each example further enhances its precision and </span>\n",
       "<span style=\"font-weight: bold\">completeness. While Answer </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\"> mentions challenges, Answer </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">'s discussion of ethical implications adds a crucial </span>\n",
       "<span style=\"font-weight: bold\">layer of detail regarding responsible implementation.</span>\n",
       "\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mSynth Evaluation: \u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\u001b[1m Justification: Answer \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m provides more specific and detailed examples of novel applications of\u001b[0m\n",
       "\u001b[1mReAct integrated with various APIs.  Each example \u001b[0m\u001b[1m(\u001b[0m\u001b[1mscientific literature, finance, legal research, simulated \u001b[0m\n",
       "\u001b[1mmedical diagnosis, personalized education\u001b[0m\u001b[1m)\u001b[0m\u001b[1m is clearly explained, including how the integration would impact both \u001b[0m\n",
       "\u001b[1mthe reasoning and action capabilities of the model.  Answer \u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m offers good examples as well, but they are less \u001b[0m\n",
       "\u001b[1mdetailed in explaining the impact on reasoning and action.  For example, \u001b[0m\u001b[32m\"Scientific Discovery and Hypothesis \u001b[0m\n",
       "\u001b[32mGeneration\"\u001b[0m\u001b[1m is mentioned but lacks the granular explanation provided by Answer \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m's \u001b[0m\u001b[32m\"Scientific Literature Retrieval\u001b[0m\n",
       "\u001b[32mand Reasoning.\"\u001b[0m\u001b[1m  Answer \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m's inclusion of ethical considerations in each example further enhances its precision and \u001b[0m\n",
       "\u001b[1mcompleteness. While Answer \u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m mentions challenges, Answer \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m's discussion of ethical implications adds a crucial \u001b[0m\n",
       "\u001b[1mlayer of detail regarding responsible implementation.\u001b[0m\n",
       "\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ragas import evaluate, EvaluationDataset, SingleTurnSample\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness, SemanticSimilarity\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "\n",
    "eval_prompt = ChatPromptTemplate.from_template(\"\"\"INSTRUCTION: \n",
    "Evaluate the following Question-Answer pair for accuracy & precision of detail.\n",
    "[1] First answer is more detailed, accurate and precise.\n",
    "[2] Second answer is more detailed, accurate and precise.\n",
    "\n",
    "Output Format:\n",
    "[Score] Justification\n",
    "\n",
    "{qa_trio}\n",
    "\n",
    "EVALUATION: \n",
    "\"\"\")\n",
    "\n",
    "pref_score = []\n",
    "trio_gen = zip(synth_questions, synth_answers, rag_answers)\n",
    "\n",
    "# For RAGAs scores\n",
    "samples = [\n",
    "    SingleTurnSample(user_input=q, retrieved_contexts=[c], response=a_rag, reference=a_synth)\n",
    "    for q, c, a_rag, a_synth in zip(synth_questions, contexts, rag_answers, synth_answers)\n",
    "]\n",
    "\n",
    "dataset = EvaluationDataset(samples)\n",
    "\n",
    "# evaluator_llm = LangchainLLMWrapper(instruct_llm)\n",
    "# evaluator_embeddings = LangchainEmbeddingsWrapper(embedder)\n",
    "\n",
    "# metrics = [LLMContextRecall(llm=evaluator_llm), FactualCorrectness(llm=evaluator_llm), Faithfulness(llm=evaluator_llm), SemanticSimilarity(embeddings=evaluator_embeddings)]\n",
    "# results = evaluate(dataset=dataset, metrics=metrics)\n",
    "\n",
    "for i, (q, a_synth, a_rag) in enumerate(trio_gen):\n",
    "    pprint2(f\"Set {i+1}\\n\\nQuestion: {q}\\n\\n\")\n",
    "    qa_trio = f\"Question: {q}\\n\\nAnswer 1: {a_rag}\\n\\n Answer 2: {a_synth}\"\n",
    "    pref_score += [(eval_prompt | llm).invoke({'qa_trio': qa_trio})]\n",
    "    pprint(f\"RAG Answer: {a_rag}\\n\\n\")\n",
    "    pprint(f\"Synth Answer: {a_synth}\\n\\n\")\n",
    "    pprint2(f\"Synth Evaluation: {pref_score[-1]}\\n\\n\")\n",
    "# pprint2(f\"RAGAs Scores: {result.scores.samples.todict()}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6595662-9f49-44eb-9868-2a3fdb1fb60f",
   "metadata": {},
   "source": [
    "We now have an LLM system that reasons about our pipeline and tries to evaluate it. Now we have some judge results, we aggregate the results and see how often our formulation was correct according to an LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "05fb77ab-0d75-4b6b-be21-c5607f5c699e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preference Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "pref_score = sum((\"[1]\" in score) for score in pref_score) / len(pref_score)\n",
    "print(f\"Preference Score: {pref_score}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
